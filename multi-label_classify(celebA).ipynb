{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "def relu(x, name='relu6'):\n",
    "    return tf.nn.relu6(x, name)\n",
    "\n",
    "\n",
    "def batch_norm(x, momentum=0.9, epsilon=1e-5, train=True, name='bn'):\n",
    "    return tf.layers.batch_normalization(x,\n",
    "                      momentum=momentum,\n",
    "                      epsilon=epsilon,\n",
    "                      scale=True,\n",
    "                      training=train,\n",
    "                      name=name)\n",
    "\n",
    "\n",
    "def conv2d(input_, output_dim, k_h, k_w, d_h, d_w, stddev=0.02, name='conv2d', bias=False):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
    "        if bias:\n",
    "            biases = tf.get_variable('bias', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        return conv\n",
    "\n",
    "\n",
    "def conv2d_block(input, out_dim, k, s, is_train, name):\n",
    "    with tf.name_scope(name), tf.variable_scope(name):\n",
    "        net = conv2d(input, out_dim, k, k, s, s, name='conv2d')\n",
    "        net = batch_norm(net, train=is_train, name='bn')\n",
    "        net = relu(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "def conv_1x1(input, output_dim, name, bias=False):\n",
    "    with tf.name_scope(name):\n",
    "        return conv2d(input, output_dim, 1, 1, 1, 1, stddev=0.02, name=name, bias=bias)\n",
    "\n",
    "\n",
    "def pwise_block(input, output_dim, is_train, name, bias=False):\n",
    "    with tf.name_scope(name), tf.variable_scope(name):\n",
    "        out = conv_1x1(input, output_dim, bias=bias, name='pwb')\n",
    "        out = batch_norm(out, train=is_train, name='bn')\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def dwise_conv(input, k_h=3, k_w=3, channel_multiplier= 1, strides=[1,1,1,1],\n",
    "               padding='SAME', stddev=0.02, name='dwise_conv', bias=False):\n",
    "    with tf.variable_scope(name):\n",
    "        in_channel=input.get_shape().as_list()[-1]\n",
    "        w = tf.get_variable('w', [k_h, k_w, in_channel, channel_multiplier],\n",
    "                        regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.depthwise_conv2d(input, w, strides, padding, rate=None,name=None,data_format=None)\n",
    "        if bias:\n",
    "            biases = tf.get_variable('bias', [in_channel*channel_multiplier], initializer=tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        return conv\n",
    "\n",
    "\n",
    "def res_block(input, expansion_ratio, output_dim, stride, is_train, name, bias=False, shortcut=True):\n",
    "    with tf.name_scope(name), tf.variable_scope(name):\n",
    "        # pw\n",
    "        bottleneck_dim=round(expansion_ratio*input.get_shape().as_list()[-1])\n",
    "        net = conv_1x1(input, bottleneck_dim, name='pw', bias=bias)\n",
    "        net = batch_norm(net, train=is_train, name='pw_bn')\n",
    "        net = relu(net)\n",
    "        # dw\n",
    "        net = dwise_conv(net, strides=[1, stride, stride, 1], name='dw', bias=bias)\n",
    "        net = batch_norm(net, train=is_train, name='dw_bn')\n",
    "        net = relu(net)\n",
    "        # pw & linear\n",
    "        net = conv_1x1(net, output_dim, name='pw_linear', bias=bias)\n",
    "        net = batch_norm(net, train=is_train, name='pw_linear_bn')\n",
    "\n",
    "        # element wise add, only for stride==1\n",
    "        if shortcut and stride == 1:\n",
    "            in_dim = int(input.get_shape().as_list()[-1])\n",
    "            if in_dim != output_dim:\n",
    "                ins = conv_1x1(input, output_dim, name='ex_dim')\n",
    "                net = ins+net\n",
    "            else:\n",
    "                net = input+net\n",
    "\n",
    "        return net\n",
    "\n",
    "\n",
    "def separable_conv(input, k_size, output_dim, stride, pad='SAME', channel_multiplier=1, name='sep_conv', bias=False):\n",
    "    with tf.name_scope(name), tf.variable_scope(name):\n",
    "        in_channel = input.get_shape().as_list()[-1]\n",
    "        dwise_filter = tf.get_variable('dw', [k_size, k_size, in_channel, channel_multiplier],\n",
    "                  regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\n",
    "                  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "        pwise_filter = tf.get_variable('pw', [1, 1, in_channel*channel_multiplier, output_dim],\n",
    "                  regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\n",
    "                  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        strides = [1, stride, stride, 1]\n",
    "\n",
    "        conv = tf.nn.separable_conv2d(input, dwise_filter, pwise_filter, strides, padding=pad, name=name)\n",
    "        if bias:\n",
    "            biases = tf.get_variable('bias', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, biases)\n",
    "        return conv\n",
    "\n",
    "\n",
    "def global_avg(x):\n",
    "    with tf.name_scope('global_avg'):\n",
    "        net = tf.layers.average_pooling2d(x, x.get_shape()[1:-1], 1)\n",
    "        return net\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    # flattened = tf.reshape(input,[x.get_shape().as_list()[0], -1])  # or, tf.layers.flatten(x)\n",
    "    return tf.contrib.layers.flatten(x)\n",
    "\n",
    "\n",
    "def pad2d(inputs, pad=(0, 0), mode='CONSTANT'):\n",
    "    paddings = [[0, 0], [pad[0], pad[0]], [pad[1], pad[1]], [0, 0]]\n",
    "    net = tf.pad(inputs, paddings, mode=mode)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv2(inputs, num_classes, is_train=True, reuse=False):\n",
    "\n",
    "    exp = 6  # expansion ratio\n",
    "\n",
    "    net = conv2d_block(inputs, 32, 3, 1, is_train, name='conv1_1')  # [64,128,96,32]\n",
    "\n",
    "    net = res_block(net, 1, 16, 1, is_train, name='res1_1')  # [64,128,96,16]\n",
    "\n",
    "    net = res_block(net, 1, 16, 2, is_train, name='res2_1')  # size/2 [64,64,48,16]\n",
    "\n",
    "    net = res_block(net, exp, 32, 2, is_train, name='res3_1')  # size/4 [64,32,24,32]\n",
    "\n",
    "    net = res_block(net, exp, 64, 2, is_train, name='res4_1')  # size/8 [64,16,12,64]\n",
    "\n",
    "    net = res_block(net, exp, 128, 2, is_train, name='res5_1')  # size/16 [64,8,6,128]\n",
    "    \n",
    "    net = res_block(net, exp, 256, 2, is_train, name='res6_1')  # size/16 [64,8,6,128]\n",
    "\n",
    "    net = pwise_block(net, 256, is_train, name='pw_conv7_1')  # [64,8,6,256]\n",
    "\n",
    "    net = global_avg(net)  # [64,1,1,256]\n",
    "\n",
    "    net = conv_1x1(net, num_classes, name='logits')  # [64,1,1,10]\n",
    "\n",
    "    logits = flatten(net)  # [64,10]\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取训练和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_after_dequeue = 32\n",
    "batch_size = 32\n",
    "capacity = min_after_dequeue+3*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.train.match_filenames_once('E:/celeA/1220/data/data.tfrecords-*')\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(files,shuffle=True)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_,serialized_example = reader.read(filename_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'image':tf.FixedLenFeature([],tf.string),\n",
    "        'label':tf.FixedLenFeature([],tf.string)\n",
    "    })\n",
    "\n",
    "img = tf.decode_raw(features['image'],tf.float32)\n",
    "image = tf.reshape(img, [128,96,3])\n",
    "l = tf.decode_raw(features['label'],tf.float32)\n",
    "label = tf.reshape(l, [42,2])\n",
    "\n",
    "batch_x,batch_y = tf.train.shuffle_batch([image,label],batch_size=batch_size,capacity=capacity,min_after_dequeue=min_after_dequeue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfiles = tf.train.match_filenames_once('E:/celeA/1220/data/test.tfrecords-*')\n",
    "vfilename_queue = tf.train.string_input_producer(files,shuffle=False)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_,vserialized_example = reader.read(vfilename_queue)\n",
    "vfeatures = tf.parse_single_example(\n",
    "    vserialized_example,\n",
    "    features={\n",
    "        'image':tf.FixedLenFeature([],tf.string),\n",
    "        'label':tf.FixedLenFeature([],tf.string)\n",
    "    })\n",
    "\n",
    "vimg = tf.decode_raw(vfeatures['image'],tf.float32)\n",
    "vimage = tf.reshape(vimg, [128,96,3])\n",
    "vl = tf.decode_raw(vfeatures['label'],tf.float32)\n",
    "vlabel = tf.reshape(vl, [42,2])\n",
    "vbatch_x,vbatch_y = tf.train.shuffle_batch([vimage,vlabel],batch_size=batch_size,capacity=capacity,min_after_dequeue=min_after_dequeue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 96\n",
    "h = 128\n",
    "c = 3\n",
    "num_class = 84\n",
    "\n",
    "n_step = 2001\n",
    "\n",
    "model_path = r'E:/celeA/1220/model/model'\n",
    "summary_path = r'E:/celeA/1220/log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0,train_loss:0.6751112937927246,train_acc:0.5803571343421936\n",
      "val_acc:0.7425595124562582\n",
      "step:1,train_loss:0.6305543184280396,train_acc:0.7485119104385376\n",
      "step:2,train_loss:0.5829688310623169,train_acc:0.7924107313156128\n",
      "step:3,train_loss:0.5380817651748657,train_acc:0.8035714030265808\n",
      "step:4,train_loss:0.5159462094306946,train_acc:0.796875\n",
      "step:5,train_loss:0.4957168698310852,train_acc:0.793154776096344\n",
      "step:6,train_loss:0.4653405547142029,train_acc:0.8072916865348816\n",
      "step:7,train_loss:0.48440298438072205,train_acc:0.784970223903656\n",
      "step:8,train_loss:0.47303786873817444,train_acc:0.7909226417541504\n",
      "step:9,train_loss:0.47282350063323975,train_acc:0.7909226417541504\n",
      "step:10,train_loss:0.45030245184898376,train_acc:0.8013392686843872\n",
      "step:11,train_loss:0.46433430910110474,train_acc:0.7864583134651184\n",
      "step:12,train_loss:0.4563777446746826,train_acc:0.7834821343421936\n",
      "step:13,train_loss:0.4601074457168579,train_acc:0.7916666865348816\n",
      "step:14,train_loss:0.46199488639831543,train_acc:0.7938988208770752\n",
      "step:15,train_loss:0.4410652816295624,train_acc:0.8028273582458496\n",
      "step:16,train_loss:0.45366159081459045,train_acc:0.793154776096344\n",
      "step:17,train_loss:0.43756529688835144,train_acc:0.8058035969734192\n",
      "step:18,train_loss:0.4705759584903717,train_acc:0.7916666865348816\n",
      "step:19,train_loss:0.39808592200279236,train_acc:0.8251488208770752\n",
      "step:20,train_loss:0.41996875405311584,train_acc:0.808779776096344\n",
      "step:21,train_loss:0.4472813904285431,train_acc:0.804315447807312\n",
      "step:22,train_loss:0.4114469885826111,train_acc:0.8236607313156128\n",
      "step:23,train_loss:0.4346171021461487,train_acc:0.7998511791229248\n",
      "step:24,train_loss:0.38987186551094055,train_acc:0.824404776096344\n",
      "step:25,train_loss:0.4121891260147095,train_acc:0.8095238208770752\n",
      "step:26,train_loss:0.4295094907283783,train_acc:0.8102678656578064\n",
      "step:27,train_loss:0.40738242864608765,train_acc:0.831845223903656\n",
      "step:28,train_loss:0.42814308404922485,train_acc:0.8139880895614624\n",
      "step:29,train_loss:0.42872515320777893,train_acc:0.8117559552192688\n",
      "step:30,train_loss:0.40630707144737244,train_acc:0.8147321343421936\n",
      "step:31,train_loss:0.43608811497688293,train_acc:0.8020833134651184\n",
      "step:32,train_loss:0.45065999031066895,train_acc:0.8028273582458496\n",
      "step:33,train_loss:0.4074939489364624,train_acc:0.808779776096344\n",
      "step:34,train_loss:0.4011879861354828,train_acc:0.8266369104385376\n",
      "step:35,train_loss:0.43388739228248596,train_acc:0.7983630895614624\n",
      "step:36,train_loss:0.4081329107284546,train_acc:0.8325892686843872\n",
      "step:37,train_loss:0.399578720331192,train_acc:0.8229166865348816\n",
      "step:38,train_loss:0.4176439940929413,train_acc:0.8177083134651184\n",
      "step:39,train_loss:0.4122820496559143,train_acc:0.8229166865348816\n",
      "step:40,train_loss:0.40008416771888733,train_acc:0.824404776096344\n",
      "step:41,train_loss:0.3886687457561493,train_acc:0.8266369104385376\n",
      "step:42,train_loss:0.37539830803871155,train_acc:0.836309552192688\n",
      "step:43,train_loss:0.3775802254676819,train_acc:0.835565447807312\n",
      "step:44,train_loss:0.43735814094543457,train_acc:0.8058035969734192\n",
      "step:45,train_loss:0.35961097478866577,train_acc:0.8482142686843872\n",
      "step:46,train_loss:0.3993230164051056,train_acc:0.819940447807312\n",
      "step:47,train_loss:0.4115537106990814,train_acc:0.8214285969734192\n",
      "step:48,train_loss:0.40012413263320923,train_acc:0.8169642686843872\n",
      "step:49,train_loss:0.38465189933776855,train_acc:0.836309552192688\n",
      "step:50,train_loss:0.39472630620002747,train_acc:0.8214285969734192\n",
      "val_acc:0.7745535771052042\n",
      "step:51,train_loss:0.38352781534194946,train_acc:0.8348214030265808\n",
      "step:52,train_loss:0.39055001735687256,train_acc:0.8296130895614624\n",
      "step:53,train_loss:0.379129022359848,train_acc:0.8251488208770752\n",
      "step:54,train_loss:0.3737771511077881,train_acc:0.8385416865348816\n",
      "step:55,train_loss:0.36101993918418884,train_acc:0.835565447807312\n",
      "step:56,train_loss:0.35473302006721497,train_acc:0.847470223903656\n",
      "step:57,train_loss:0.3624213635921478,train_acc:0.8392857313156128\n",
      "step:58,train_loss:0.380036324262619,train_acc:0.8303571343421936\n",
      "step:59,train_loss:0.3644656836986542,train_acc:0.8340773582458496\n",
      "step:60,train_loss:0.3758290708065033,train_acc:0.8385416865348816\n",
      "step:61,train_loss:0.3868134915828705,train_acc:0.840029776096344\n",
      "step:62,train_loss:0.38117513060569763,train_acc:0.8296130895614624\n",
      "step:63,train_loss:0.34318822622299194,train_acc:0.855654776096344\n",
      "step:64,train_loss:0.36485180258750916,train_acc:0.8377976417541504\n",
      "step:65,train_loss:0.35134878754615784,train_acc:0.8497023582458496\n",
      "step:66,train_loss:0.40344464778900146,train_acc:0.8333333134651184\n",
      "step:67,train_loss:0.33268237113952637,train_acc:0.8653273582458496\n",
      "step:68,train_loss:0.39238297939300537,train_acc:0.8303571343421936\n",
      "step:69,train_loss:0.39127621054649353,train_acc:0.8273809552192688\n",
      "step:70,train_loss:0.38524386286735535,train_acc:0.8392857313156128\n",
      "step:71,train_loss:0.33583009243011475,train_acc:0.8571428656578064\n",
      "step:72,train_loss:0.3633098006248474,train_acc:0.8467261791229248\n",
      "step:73,train_loss:0.4117860198020935,train_acc:0.808779776096344\n",
      "step:74,train_loss:0.35510459542274475,train_acc:0.84375\n",
      "step:75,train_loss:0.3775414526462555,train_acc:0.8407738208770752\n",
      "step:76,train_loss:0.37357640266418457,train_acc:0.8325892686843872\n",
      "step:77,train_loss:0.39260005950927734,train_acc:0.824404776096344\n",
      "step:78,train_loss:0.3505479395389557,train_acc:0.8444940447807312\n",
      "step:79,train_loss:0.34641388058662415,train_acc:0.8407738208770752\n",
      "step:80,train_loss:0.3490525782108307,train_acc:0.8526785969734192\n",
      "step:81,train_loss:0.3532586395740509,train_acc:0.8541666865348816\n",
      "step:82,train_loss:0.38561466336250305,train_acc:0.8311011791229248\n",
      "step:83,train_loss:0.36974576115608215,train_acc:0.8407738208770752\n",
      "step:84,train_loss:0.3517964482307434,train_acc:0.8504464030265808\n",
      "step:85,train_loss:0.34639230370521545,train_acc:0.8482142686843872\n",
      "step:86,train_loss:0.3629510700702667,train_acc:0.8452380895614624\n",
      "step:87,train_loss:0.3339889943599701,train_acc:0.8504464030265808\n",
      "step:88,train_loss:0.32856300473213196,train_acc:0.871279776096344\n",
      "step:89,train_loss:0.3361557722091675,train_acc:0.859375\n",
      "step:90,train_loss:0.3720345199108124,train_acc:0.8415178656578064\n",
      "step:91,train_loss:0.3729376196861267,train_acc:0.8430059552192688\n",
      "step:92,train_loss:0.32302168011665344,train_acc:0.8541666865348816\n",
      "step:93,train_loss:0.3745582699775696,train_acc:0.8444940447807312\n",
      "step:94,train_loss:0.34110701084136963,train_acc:0.8497023582458496\n",
      "step:95,train_loss:0.3334404528141022,train_acc:0.847470223903656\n",
      "step:96,train_loss:0.338661253452301,train_acc:0.8549107313156128\n",
      "step:97,train_loss:0.3544311225414276,train_acc:0.8467261791229248\n",
      "step:98,train_loss:0.3526957333087921,train_acc:0.84375\n",
      "step:99,train_loss:0.3452407717704773,train_acc:0.8482142686843872\n",
      "step:100,train_loss:0.3195781111717224,train_acc:0.8623511791229248\n",
      "val_acc:0.8288690646489462\n",
      "step:101,train_loss:0.33805838227272034,train_acc:0.851934552192688\n",
      "step:102,train_loss:0.31595465540885925,train_acc:0.8653273582458496\n",
      "step:103,train_loss:0.3208274841308594,train_acc:0.8616071343421936\n",
      "step:104,train_loss:0.3149203658103943,train_acc:0.8705357313156128\n",
      "step:105,train_loss:0.3371266722679138,train_acc:0.8541666865348816\n",
      "step:106,train_loss:0.34546566009521484,train_acc:0.859375\n",
      "step:107,train_loss:0.3153108060359955,train_acc:0.866815447807312\n",
      "step:108,train_loss:0.3308069109916687,train_acc:0.8578869104385376\n",
      "step:109,train_loss:0.3539080023765564,train_acc:0.8377976417541504\n",
      "step:110,train_loss:0.337478905916214,train_acc:0.8586309552192688\n",
      "step:111,train_loss:0.3176056444644928,train_acc:0.8586309552192688\n",
      "step:112,train_loss:0.33517757058143616,train_acc:0.8578869104385376\n",
      "step:113,train_loss:0.3076784908771515,train_acc:0.8705357313156128\n",
      "step:114,train_loss:0.35053831338882446,train_acc:0.836309552192688\n",
      "step:115,train_loss:0.3021438717842102,train_acc:0.871279776096344\n",
      "step:116,train_loss:0.3002995550632477,train_acc:0.883184552192688\n",
      "step:117,train_loss:0.3435819447040558,train_acc:0.8504464030265808\n",
      "step:118,train_loss:0.31526583433151245,train_acc:0.8645833134651184\n",
      "step:119,train_loss:0.31457817554473877,train_acc:0.8526785969734192\n",
      "step:120,train_loss:0.3006436824798584,train_acc:0.8683035969734192\n",
      "step:121,train_loss:0.3155957758426666,train_acc:0.8623511791229248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:122,train_loss:0.30612075328826904,train_acc:0.8705357313156128\n",
      "step:123,train_loss:0.3273783028125763,train_acc:0.867559552192688\n",
      "step:124,train_loss:0.31610724329948425,train_acc:0.8623511791229248\n",
      "step:125,train_loss:0.348629891872406,train_acc:0.855654776096344\n",
      "step:126,train_loss:0.2901322841644287,train_acc:0.8809523582458496\n",
      "step:127,train_loss:0.33531123399734497,train_acc:0.8504464030265808\n",
      "step:128,train_loss:0.3365781307220459,train_acc:0.8645833134651184\n",
      "step:129,train_loss:0.30431225895881653,train_acc:0.8653273582458496\n",
      "step:130,train_loss:0.32821744680404663,train_acc:0.8526785969734192\n",
      "step:131,train_loss:0.32523486018180847,train_acc:0.8616071343421936\n",
      "step:132,train_loss:0.3319903612136841,train_acc:0.851934552192688\n",
      "step:133,train_loss:0.323744535446167,train_acc:0.8653273582458496\n",
      "step:134,train_loss:0.32884469628334045,train_acc:0.851934552192688\n",
      "step:135,train_loss:0.330759197473526,train_acc:0.8616071343421936\n",
      "step:136,train_loss:0.3440247178077698,train_acc:0.840029776096344\n",
      "step:137,train_loss:0.32621288299560547,train_acc:0.863095223903656\n",
      "step:138,train_loss:0.2919584810733795,train_acc:0.8772321343421936\n",
      "step:139,train_loss:0.29414689540863037,train_acc:0.867559552192688\n",
      "step:140,train_loss:0.2821092903614044,train_acc:0.8846726417541504\n",
      "step:141,train_loss:0.3149833381175995,train_acc:0.8660714030265808\n",
      "step:142,train_loss:0.3360932767391205,train_acc:0.855654776096344\n",
      "step:143,train_loss:0.2973373830318451,train_acc:0.8697916865348816\n",
      "step:144,train_loss:0.32254117727279663,train_acc:0.84375\n",
      "step:145,train_loss:0.31256282329559326,train_acc:0.866815447807312\n",
      "step:146,train_loss:0.28247103095054626,train_acc:0.8764880895614624\n",
      "step:147,train_loss:0.29357218742370605,train_acc:0.8697916865348816\n",
      "step:148,train_loss:0.2878745496273041,train_acc:0.8809523582458496\n",
      "step:149,train_loss:0.3162030279636383,train_acc:0.8578869104385376\n",
      "step:150,train_loss:0.33960986137390137,train_acc:0.8482142686843872\n",
      "val_acc:0.8623511989911398\n",
      "step:151,train_loss:0.30425065755844116,train_acc:0.8735119104385376\n",
      "step:152,train_loss:0.28329744935035706,train_acc:0.8764880895614624\n",
      "step:153,train_loss:0.2912368178367615,train_acc:0.875\n",
      "step:154,train_loss:0.3300822377204895,train_acc:0.8608630895614624\n",
      "step:155,train_loss:0.2875186502933502,train_acc:0.875\n",
      "step:156,train_loss:0.32440581917762756,train_acc:0.8586309552192688\n",
      "step:157,train_loss:0.3194947838783264,train_acc:0.8697916865348816\n",
      "step:158,train_loss:0.3182637393474579,train_acc:0.8616071343421936\n",
      "step:159,train_loss:0.3104228079319,train_acc:0.8660714030265808\n",
      "step:160,train_loss:0.2939222753047943,train_acc:0.8653273582458496\n",
      "step:161,train_loss:0.29530948400497437,train_acc:0.866815447807312\n",
      "step:162,train_loss:0.3205088675022125,train_acc:0.863095223903656\n",
      "step:163,train_loss:0.3215292692184448,train_acc:0.8482142686843872\n",
      "step:164,train_loss:0.30059394240379333,train_acc:0.8720238208770752\n",
      "step:165,train_loss:0.29451361298561096,train_acc:0.8757440447807312\n",
      "step:166,train_loss:0.318344384431839,train_acc:0.8660714030265808\n",
      "step:167,train_loss:0.2950808107852936,train_acc:0.867559552192688\n",
      "step:168,train_loss:0.2890736162662506,train_acc:0.8720238208770752\n",
      "step:169,train_loss:0.27706432342529297,train_acc:0.871279776096344\n",
      "step:170,train_loss:0.275887131690979,train_acc:0.8757440447807312\n",
      "step:171,train_loss:0.29250234365463257,train_acc:0.8720238208770752\n",
      "step:172,train_loss:0.305074006319046,train_acc:0.8697916865348816\n",
      "step:173,train_loss:0.2856341302394867,train_acc:0.8727678656578064\n",
      "step:174,train_loss:0.26490139961242676,train_acc:0.886904776096344\n",
      "step:175,train_loss:0.29270845651626587,train_acc:0.875\n",
      "step:176,train_loss:0.27383264899253845,train_acc:0.882440447807312\n",
      "step:177,train_loss:0.2646355628967285,train_acc:0.8794642686843872\n",
      "step:178,train_loss:0.306779146194458,train_acc:0.8616071343421936\n",
      "step:179,train_loss:0.27984073758125305,train_acc:0.8764880895614624\n",
      "step:180,train_loss:0.29441720247268677,train_acc:0.8683035969734192\n",
      "step:181,train_loss:0.2789069414138794,train_acc:0.8802083134651184\n",
      "step:182,train_loss:0.267022043466568,train_acc:0.883184552192688\n",
      "step:183,train_loss:0.27876409888267517,train_acc:0.882440447807312\n",
      "step:184,train_loss:0.3077274560928345,train_acc:0.8653273582458496\n",
      "step:185,train_loss:0.3108881115913391,train_acc:0.8705357313156128\n",
      "step:186,train_loss:0.29145026206970215,train_acc:0.8727678656578064\n",
      "step:187,train_loss:0.28629669547080994,train_acc:0.866815447807312\n",
      "step:188,train_loss:0.2759810984134674,train_acc:0.8854166865348816\n",
      "step:189,train_loss:0.30777066946029663,train_acc:0.8571428656578064\n",
      "step:190,train_loss:0.30484646558761597,train_acc:0.8779761791229248\n",
      "step:191,train_loss:0.28616803884506226,train_acc:0.8802083134651184\n",
      "step:192,train_loss:0.2964800000190735,train_acc:0.871279776096344\n",
      "step:193,train_loss:0.2966700494289398,train_acc:0.871279776096344\n",
      "step:194,train_loss:0.2961716055870056,train_acc:0.871279776096344\n",
      "step:195,train_loss:0.2972598671913147,train_acc:0.8735119104385376\n",
      "step:196,train_loss:0.28883984684944153,train_acc:0.8660714030265808\n",
      "step:197,train_loss:0.28302130103111267,train_acc:0.8802083134651184\n",
      "step:198,train_loss:0.2805345952510834,train_acc:0.8727678656578064\n",
      "step:199,train_loss:0.2805600166320801,train_acc:0.8772321343421936\n",
      "step:200,train_loss:0.28665784001350403,train_acc:0.867559552192688\n",
      "val_acc:0.8764881094296774\n",
      "step:201,train_loss:0.2801283299922943,train_acc:0.883184552192688\n",
      "step:202,train_loss:0.27493271231651306,train_acc:0.8861607313156128\n",
      "step:203,train_loss:0.26568475365638733,train_acc:0.882440447807312\n",
      "step:204,train_loss:0.27519887685775757,train_acc:0.878720223903656\n",
      "step:205,train_loss:0.29041507840156555,train_acc:0.8735119104385376\n",
      "step:206,train_loss:0.2815580666065216,train_acc:0.8720238208770752\n",
      "step:207,train_loss:0.2746782898902893,train_acc:0.8846726417541504\n",
      "step:208,train_loss:0.26512590050697327,train_acc:0.8809523582458496\n",
      "step:209,train_loss:0.30946770310401917,train_acc:0.867559552192688\n",
      "step:210,train_loss:0.26705217361450195,train_acc:0.8876488208770752\n",
      "step:211,train_loss:0.29407253861427307,train_acc:0.8601190447807312\n",
      "step:212,train_loss:0.2843499481678009,train_acc:0.875\n",
      "step:213,train_loss:0.27340731024742126,train_acc:0.875\n",
      "step:214,train_loss:0.25362950563430786,train_acc:0.898809552192688\n",
      "step:215,train_loss:0.3134506642818451,train_acc:0.859375\n",
      "step:216,train_loss:0.26525378227233887,train_acc:0.8876488208770752\n",
      "step:217,train_loss:0.2787987291812897,train_acc:0.8876488208770752\n",
      "step:218,train_loss:0.27357614040374756,train_acc:0.8727678656578064\n",
      "step:219,train_loss:0.2995387315750122,train_acc:0.8645833134651184\n",
      "step:220,train_loss:0.2710261642932892,train_acc:0.8839285969734192\n",
      "step:221,train_loss:0.2715107202529907,train_acc:0.8816964030265808\n",
      "step:222,train_loss:0.2863641381263733,train_acc:0.8742559552192688\n",
      "step:223,train_loss:0.27231770753860474,train_acc:0.8854166865348816\n",
      "step:224,train_loss:0.2569221258163452,train_acc:0.8876488208770752\n",
      "step:225,train_loss:0.27891063690185547,train_acc:0.8779761791229248\n",
      "step:226,train_loss:0.2992021441459656,train_acc:0.8690476417541504\n",
      "step:227,train_loss:0.2787531316280365,train_acc:0.8816964030265808\n",
      "step:228,train_loss:0.25887617468833923,train_acc:0.8928571343421936\n",
      "step:229,train_loss:0.2923355996608734,train_acc:0.8727678656578064\n",
      "step:230,train_loss:0.2812144458293915,train_acc:0.8720238208770752\n",
      "step:231,train_loss:0.27570757269859314,train_acc:0.878720223903656\n",
      "step:232,train_loss:0.257098525762558,train_acc:0.894345223903656\n",
      "step:233,train_loss:0.2646114230155945,train_acc:0.8764880895614624\n",
      "step:234,train_loss:0.27464985847473145,train_acc:0.8846726417541504\n",
      "step:235,train_loss:0.2652651071548462,train_acc:0.8854166865348816\n",
      "step:236,train_loss:0.28854650259017944,train_acc:0.8705357313156128\n",
      "step:237,train_loss:0.266325443983078,train_acc:0.883184552192688\n",
      "step:238,train_loss:0.2848282754421234,train_acc:0.8742559552192688\n",
      "step:239,train_loss:0.28402698040008545,train_acc:0.871279776096344\n",
      "step:240,train_loss:0.26230838894844055,train_acc:0.8846726417541504\n",
      "step:241,train_loss:0.2730417847633362,train_acc:0.8772321343421936\n",
      "step:242,train_loss:0.2911165654659271,train_acc:0.8653273582458496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:243,train_loss:0.25921717286109924,train_acc:0.8839285969734192\n",
      "step:244,train_loss:0.27415451407432556,train_acc:0.8816964030265808\n",
      "step:245,train_loss:0.2799224257469177,train_acc:0.8772321343421936\n",
      "step:246,train_loss:0.2684113085269928,train_acc:0.8802083134651184\n",
      "step:247,train_loss:0.26734262704849243,train_acc:0.8757440447807312\n",
      "step:248,train_loss:0.2426847219467163,train_acc:0.9017857313156128\n",
      "step:249,train_loss:0.2895931899547577,train_acc:0.8720238208770752\n",
      "step:250,train_loss:0.27751049399375916,train_acc:0.8764880895614624\n",
      "val_acc:0.8839285572369894\n",
      "step:251,train_loss:0.26513856649398804,train_acc:0.8913690447807312\n",
      "step:252,train_loss:0.23862527310848236,train_acc:0.9002976417541504\n",
      "step:253,train_loss:0.2629919946193695,train_acc:0.8802083134651184\n",
      "step:254,train_loss:0.24753643572330475,train_acc:0.8965773582458496\n",
      "step:255,train_loss:0.2588609755039215,train_acc:0.8898809552192688\n",
      "step:256,train_loss:0.257335901260376,train_acc:0.8913690447807312\n",
      "step:257,train_loss:0.26196569204330444,train_acc:0.8809523582458496\n",
      "step:258,train_loss:0.2516361474990845,train_acc:0.8936011791229248\n",
      "step:259,train_loss:0.2394217550754547,train_acc:0.8958333134651184\n",
      "step:260,train_loss:0.24143414199352264,train_acc:0.9002976417541504\n",
      "step:261,train_loss:0.24145235121250153,train_acc:0.8936011791229248\n",
      "step:262,train_loss:0.257549524307251,train_acc:0.8950892686843872\n",
      "step:263,train_loss:0.28096890449523926,train_acc:0.875\n",
      "step:264,train_loss:0.2621901035308838,train_acc:0.8846726417541504\n",
      "step:265,train_loss:0.2549417018890381,train_acc:0.8891369104385376\n",
      "step:266,train_loss:0.2512284815311432,train_acc:0.8883928656578064\n",
      "step:267,train_loss:0.2698981463909149,train_acc:0.8809523582458496\n",
      "step:268,train_loss:0.2519811987876892,train_acc:0.8995535969734192\n",
      "step:269,train_loss:0.2540450692176819,train_acc:0.898065447807312\n",
      "step:270,train_loss:0.24012692272663116,train_acc:0.9040178656578064\n",
      "step:271,train_loss:0.270881712436676,train_acc:0.8809523582458496\n",
      "step:272,train_loss:0.2354566901922226,train_acc:0.8965773582458496\n",
      "step:273,train_loss:0.25583580136299133,train_acc:0.8891369104385376\n",
      "step:274,train_loss:0.2514486312866211,train_acc:0.8794642686843872\n",
      "step:275,train_loss:0.28734278678894043,train_acc:0.8683035969734192\n",
      "step:276,train_loss:0.2797910273075104,train_acc:0.875\n",
      "step:277,train_loss:0.25666987895965576,train_acc:0.883184552192688\n",
      "step:278,train_loss:0.25925347208976746,train_acc:0.8928571343421936\n",
      "step:279,train_loss:0.2422412633895874,train_acc:0.8854166865348816\n",
      "step:280,train_loss:0.26321619749069214,train_acc:0.890625\n",
      "step:281,train_loss:0.23994433879852295,train_acc:0.8995535969734192\n",
      "step:282,train_loss:0.2434128373861313,train_acc:0.8995535969734192\n",
      "step:283,train_loss:0.2576167583465576,train_acc:0.8950892686843872\n",
      "step:284,train_loss:0.2385486364364624,train_acc:0.8928571343421936\n",
      "step:285,train_loss:0.244090735912323,train_acc:0.8898809552192688\n",
      "step:286,train_loss:0.250264048576355,train_acc:0.8809523582458496\n",
      "step:287,train_loss:0.24842852354049683,train_acc:0.8928571343421936\n",
      "step:288,train_loss:0.24105298519134521,train_acc:0.898809552192688\n",
      "step:289,train_loss:0.22983819246292114,train_acc:0.9047619104385376\n",
      "step:290,train_loss:0.23940472304821014,train_acc:0.898065447807312\n",
      "step:291,train_loss:0.24454104900360107,train_acc:0.8876488208770752\n",
      "step:292,train_loss:0.25288358330726624,train_acc:0.8921130895614624\n",
      "step:293,train_loss:0.27573323249816895,train_acc:0.890625\n",
      "step:294,train_loss:0.2428848147392273,train_acc:0.890625\n",
      "step:295,train_loss:0.25150948762893677,train_acc:0.8928571343421936\n",
      "step:296,train_loss:0.2609468996524811,train_acc:0.883184552192688\n",
      "step:297,train_loss:0.2630297839641571,train_acc:0.8898809552192688\n",
      "step:298,train_loss:0.252052903175354,train_acc:0.8764880895614624\n",
      "step:299,train_loss:0.24640923738479614,train_acc:0.8802083134651184\n",
      "step:300,train_loss:0.225019633769989,train_acc:0.8995535969734192\n",
      "val_acc:0.8908730347951254\n",
      "step:301,train_loss:0.26243719458580017,train_acc:0.8876488208770752\n",
      "step:302,train_loss:0.2547348141670227,train_acc:0.886904776096344\n",
      "step:303,train_loss:0.2882100045681,train_acc:0.8802083134651184\n",
      "step:304,train_loss:0.2744041681289673,train_acc:0.8854166865348816\n",
      "step:305,train_loss:0.2677081823348999,train_acc:0.8772321343421936\n",
      "step:306,train_loss:0.2456178218126297,train_acc:0.8861607313156128\n",
      "step:307,train_loss:0.23181864619255066,train_acc:0.9084821343421936\n",
      "step:308,train_loss:0.23362194001674652,train_acc:0.9032738208770752\n",
      "step:309,train_loss:0.2303168922662735,train_acc:0.8973214030265808\n",
      "step:310,train_loss:0.22580814361572266,train_acc:0.9010416865348816\n",
      "step:311,train_loss:0.24532859027385712,train_acc:0.8898809552192688\n",
      "step:312,train_loss:0.24657951295375824,train_acc:0.894345223903656\n",
      "step:313,train_loss:0.2253793329000473,train_acc:0.8973214030265808\n",
      "step:314,train_loss:0.21057792007923126,train_acc:0.9211309552192688\n",
      "step:315,train_loss:0.22085748612880707,train_acc:0.913690447807312\n",
      "step:316,train_loss:0.2559663653373718,train_acc:0.8876488208770752\n",
      "step:317,train_loss:0.23184163868427277,train_acc:0.9055059552192688\n",
      "step:318,train_loss:0.22847577929496765,train_acc:0.9032738208770752\n",
      "step:319,train_loss:0.22293774783611298,train_acc:0.9077380895614624\n",
      "step:320,train_loss:0.23719346523284912,train_acc:0.8965773582458496\n",
      "step:321,train_loss:0.2466786950826645,train_acc:0.8913690447807312\n",
      "step:322,train_loss:0.24462950229644775,train_acc:0.8928571343421936\n",
      "step:323,train_loss:0.2333873063325882,train_acc:0.8913690447807312\n",
      "step:324,train_loss:0.2830951511859894,train_acc:0.8757440447807312\n",
      "step:325,train_loss:0.23432883620262146,train_acc:0.9055059552192688\n",
      "step:326,train_loss:0.24283888936042786,train_acc:0.9040178656578064\n",
      "step:327,train_loss:0.2340662181377411,train_acc:0.8995535969734192\n",
      "step:328,train_loss:0.22979514300823212,train_acc:0.9010416865348816\n",
      "step:329,train_loss:0.22878921031951904,train_acc:0.9010416865348816\n",
      "step:330,train_loss:0.24194100499153137,train_acc:0.8921130895614624\n",
      "step:331,train_loss:0.24376660585403442,train_acc:0.8921130895614624\n",
      "step:332,train_loss:0.24444957077503204,train_acc:0.8883928656578064\n",
      "step:333,train_loss:0.24523480236530304,train_acc:0.8950892686843872\n",
      "step:334,train_loss:0.2691015601158142,train_acc:0.8816964030265808\n",
      "step:335,train_loss:0.2466065138578415,train_acc:0.898065447807312\n",
      "step:336,train_loss:0.22748838365077972,train_acc:0.9032738208770752\n",
      "step:337,train_loss:0.2171572744846344,train_acc:0.9084821343421936\n",
      "step:338,train_loss:0.2352093756198883,train_acc:0.9017857313156128\n",
      "step:339,train_loss:0.23261244595050812,train_acc:0.9077380895614624\n",
      "step:340,train_loss:0.2380257099866867,train_acc:0.8965773582458496\n",
      "step:341,train_loss:0.2990601658821106,train_acc:0.8742559552192688\n",
      "step:342,train_loss:0.22630664706230164,train_acc:0.90625\n",
      "step:343,train_loss:0.22648823261260986,train_acc:0.8965773582458496\n",
      "step:344,train_loss:0.21537712216377258,train_acc:0.9077380895614624\n",
      "step:345,train_loss:0.217878520488739,train_acc:0.913690447807312\n",
      "step:346,train_loss:0.22494129836559296,train_acc:0.9047619104385376\n",
      "step:347,train_loss:0.23225529491901398,train_acc:0.9032738208770752\n",
      "step:348,train_loss:0.21771998703479767,train_acc:0.9077380895614624\n",
      "step:349,train_loss:0.2251317799091339,train_acc:0.8995535969734192\n",
      "step:350,train_loss:0.22170741856098175,train_acc:0.9055059552192688\n",
      "val_acc:0.8983134826024374\n",
      "step:351,train_loss:0.23245012760162354,train_acc:0.9092261791229248\n",
      "step:352,train_loss:0.23838597536087036,train_acc:0.8958333134651184\n",
      "step:353,train_loss:0.21965435147285461,train_acc:0.90625\n",
      "step:354,train_loss:0.21916212141513824,train_acc:0.909970223903656\n",
      "step:355,train_loss:0.21272976696491241,train_acc:0.9122023582458496\n",
      "step:356,train_loss:0.231840580701828,train_acc:0.9017857313156128\n",
      "step:357,train_loss:0.2960633635520935,train_acc:0.8608630895614624\n",
      "step:358,train_loss:0.2293136715888977,train_acc:0.90625\n",
      "step:359,train_loss:0.20533929765224457,train_acc:0.9159226417541504\n",
      "step:360,train_loss:0.21768084168434143,train_acc:0.9055059552192688\n",
      "step:361,train_loss:0.2273462414741516,train_acc:0.898809552192688\n",
      "step:362,train_loss:0.24621284008026123,train_acc:0.898065447807312\n",
      "step:363,train_loss:0.21279582381248474,train_acc:0.9151785969734192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:364,train_loss:0.19225402176380157,train_acc:0.921875\n",
      "step:365,train_loss:0.21553079783916473,train_acc:0.9114583134651184\n",
      "step:366,train_loss:0.21573588252067566,train_acc:0.9084821343421936\n",
      "step:367,train_loss:0.2154703587293625,train_acc:0.9069940447807312\n",
      "step:368,train_loss:0.2235533446073532,train_acc:0.9055059552192688\n",
      "step:369,train_loss:0.21064095199108124,train_acc:0.9151785969734192\n",
      "step:370,train_loss:0.19580155611038208,train_acc:0.9196428656578064\n",
      "step:371,train_loss:0.2267788201570511,train_acc:0.9047619104385376\n",
      "step:372,train_loss:0.20976795256137848,train_acc:0.914434552192688\n",
      "step:373,train_loss:0.20124666392803192,train_acc:0.9248511791229248\n",
      "step:374,train_loss:0.2112417221069336,train_acc:0.9055059552192688\n",
      "step:375,train_loss:0.23053637146949768,train_acc:0.902529776096344\n",
      "step:376,train_loss:0.2226959466934204,train_acc:0.9032738208770752\n",
      "step:377,train_loss:0.2335834801197052,train_acc:0.9047619104385376\n",
      "step:378,train_loss:0.21776239573955536,train_acc:0.9122023582458496\n",
      "step:379,train_loss:0.20566757023334503,train_acc:0.9188988208770752\n",
      "step:380,train_loss:0.18883396685123444,train_acc:0.9233630895614624\n",
      "step:381,train_loss:0.20565105974674225,train_acc:0.9203869104385376\n",
      "step:382,train_loss:0.2136451005935669,train_acc:0.9040178656578064\n",
      "step:383,train_loss:0.2198379635810852,train_acc:0.9107142686843872\n",
      "step:384,train_loss:0.23107987642288208,train_acc:0.9032738208770752\n",
      "step:385,train_loss:0.20638057589530945,train_acc:0.914434552192688\n",
      "step:386,train_loss:0.2121177464723587,train_acc:0.921875\n",
      "step:387,train_loss:0.21615931391716003,train_acc:0.8995535969734192\n",
      "step:388,train_loss:0.23515479266643524,train_acc:0.902529776096344\n",
      "step:389,train_loss:0.20737075805664062,train_acc:0.918154776096344\n",
      "step:390,train_loss:0.20881037414073944,train_acc:0.9077380895614624\n",
      "step:391,train_loss:0.19518566131591797,train_acc:0.9196428656578064\n",
      "step:392,train_loss:0.2020418494939804,train_acc:0.9174107313156128\n",
      "step:393,train_loss:0.20703142881393433,train_acc:0.9055059552192688\n",
      "step:394,train_loss:0.2178848385810852,train_acc:0.9047619104385376\n",
      "step:395,train_loss:0.2084600329399109,train_acc:0.9069940447807312\n",
      "step:396,train_loss:0.20060674846172333,train_acc:0.9084821343421936\n",
      "step:397,train_loss:0.1918826401233673,train_acc:0.9233630895614624\n",
      "step:398,train_loss:0.19339463114738464,train_acc:0.918154776096344\n",
      "step:399,train_loss:0.20513425767421722,train_acc:0.9107142686843872\n",
      "step:400,train_loss:0.22232010960578918,train_acc:0.9084821343421936\n",
      "val_acc:0.918154756228129\n",
      "step:401,train_loss:0.20839296281337738,train_acc:0.913690447807312\n",
      "step:402,train_loss:0.19439910352230072,train_acc:0.918154776096344\n",
      "step:403,train_loss:0.21723325550556183,train_acc:0.9017857313156128\n",
      "step:404,train_loss:0.21784435212612152,train_acc:0.9055059552192688\n",
      "step:405,train_loss:0.19090193510055542,train_acc:0.9263392686843872\n",
      "step:406,train_loss:0.19825541973114014,train_acc:0.9188988208770752\n",
      "step:407,train_loss:0.18839025497436523,train_acc:0.9278273582458496\n",
      "step:408,train_loss:0.1911161094903946,train_acc:0.921875\n",
      "step:409,train_loss:0.19992879033088684,train_acc:0.918154776096344\n",
      "step:410,train_loss:0.20087823271751404,train_acc:0.9270833134651184\n",
      "step:411,train_loss:0.20979031920433044,train_acc:0.9114583134651184\n",
      "step:412,train_loss:0.21019858121871948,train_acc:0.9077380895614624\n",
      "step:413,train_loss:0.2093622386455536,train_acc:0.902529776096344\n",
      "step:414,train_loss:0.19639647006988525,train_acc:0.9196428656578064\n",
      "step:415,train_loss:0.1909976303577423,train_acc:0.9159226417541504\n",
      "step:416,train_loss:0.21929419040679932,train_acc:0.9040178656578064\n",
      "step:417,train_loss:0.20300833880901337,train_acc:0.9174107313156128\n",
      "step:418,train_loss:0.19724880158901215,train_acc:0.9203869104385376\n",
      "step:419,train_loss:0.20526182651519775,train_acc:0.909970223903656\n",
      "step:420,train_loss:0.1953112781047821,train_acc:0.9159226417541504\n",
      "step:421,train_loss:0.18964220583438873,train_acc:0.9174107313156128\n",
      "step:422,train_loss:0.1728929579257965,train_acc:0.9330357313156128\n",
      "step:423,train_loss:0.1916840374469757,train_acc:0.9248511791229248\n",
      "step:424,train_loss:0.21115462481975555,train_acc:0.9122023582458496\n",
      "step:425,train_loss:0.1748766154050827,train_acc:0.9308035969734192\n",
      "step:426,train_loss:0.1893579661846161,train_acc:0.9241071343421936\n",
      "step:427,train_loss:0.19323435425758362,train_acc:0.9166666865348816\n",
      "step:428,train_loss:0.2124910056591034,train_acc:0.9077380895614624\n",
      "step:429,train_loss:0.17837455868721008,train_acc:0.9248511791229248\n",
      "step:430,train_loss:0.17742054164409637,train_acc:0.9233630895614624\n",
      "step:431,train_loss:0.17159944772720337,train_acc:0.9389880895614624\n",
      "step:432,train_loss:0.19579149782657623,train_acc:0.9188988208770752\n",
      "step:433,train_loss:0.19569571316242218,train_acc:0.9129464030265808\n",
      "step:434,train_loss:0.19414766132831573,train_acc:0.918154776096344\n",
      "step:435,train_loss:0.19923582673072815,train_acc:0.9107142686843872\n",
      "step:436,train_loss:0.19005270302295685,train_acc:0.9159226417541504\n",
      "step:437,train_loss:0.2067800909280777,train_acc:0.9114583134651184\n",
      "step:438,train_loss:0.20057876408100128,train_acc:0.9084821343421936\n",
      "step:439,train_loss:0.16845567524433136,train_acc:0.9367559552192688\n",
      "step:440,train_loss:0.17758017778396606,train_acc:0.9285714030265808\n",
      "step:441,train_loss:0.18813791871070862,train_acc:0.9203869104385376\n",
      "step:442,train_loss:0.23133385181427002,train_acc:0.902529776096344\n",
      "step:443,train_loss:0.23224081099033356,train_acc:0.894345223903656\n",
      "step:444,train_loss:0.1939283162355423,train_acc:0.921875\n",
      "step:445,train_loss:0.20551373064517975,train_acc:0.909970223903656\n",
      "step:446,train_loss:0.19708269834518433,train_acc:0.9203869104385376\n",
      "step:447,train_loss:0.20037014782428741,train_acc:0.9166666865348816\n",
      "step:448,train_loss:0.17631720006465912,train_acc:0.9285714030265808\n",
      "step:449,train_loss:0.18249987065792084,train_acc:0.9196428656578064\n",
      "step:450,train_loss:0.2014189213514328,train_acc:0.9203869104385376\n",
      "val_acc:0.9285714427630106\n",
      "step:451,train_loss:0.18885642290115356,train_acc:0.9188988208770752\n",
      "step:452,train_loss:0.19473974406719208,train_acc:0.9226190447807312\n",
      "step:453,train_loss:0.20127546787261963,train_acc:0.9174107313156128\n",
      "step:454,train_loss:0.1851499229669571,train_acc:0.9233630895614624\n",
      "step:455,train_loss:0.1678735464811325,train_acc:0.9375\n",
      "step:456,train_loss:0.19007596373558044,train_acc:0.9233630895614624\n",
      "step:457,train_loss:0.17548006772994995,train_acc:0.9278273582458496\n",
      "step:458,train_loss:0.1783474236726761,train_acc:0.930059552192688\n",
      "step:459,train_loss:0.20027682185173035,train_acc:0.9151785969734192\n",
      "step:460,train_loss:0.17633329331874847,train_acc:0.9270833134651184\n",
      "step:461,train_loss:0.2091197520494461,train_acc:0.9084821343421936\n",
      "step:462,train_loss:0.18689179420471191,train_acc:0.930059552192688\n",
      "step:463,train_loss:0.18634387850761414,train_acc:0.9270833134651184\n",
      "step:464,train_loss:0.17100711166858673,train_acc:0.9315476417541504\n",
      "step:465,train_loss:0.1998874545097351,train_acc:0.918154776096344\n",
      "step:466,train_loss:0.17424777150154114,train_acc:0.9308035969734192\n",
      "step:467,train_loss:0.1926531046628952,train_acc:0.921875\n",
      "step:468,train_loss:0.19587723910808563,train_acc:0.9166666865348816\n",
      "step:469,train_loss:0.19730627536773682,train_acc:0.9241071343421936\n",
      "step:470,train_loss:0.18832895159721375,train_acc:0.9151785969734192\n",
      "step:471,train_loss:0.17375077307224274,train_acc:0.921875\n",
      "step:472,train_loss:0.19687947630882263,train_acc:0.9196428656578064\n",
      "step:473,train_loss:0.1897328794002533,train_acc:0.918154776096344\n",
      "step:474,train_loss:0.21175870299339294,train_acc:0.9166666865348816\n",
      "step:475,train_loss:0.17572438716888428,train_acc:0.925595223903656\n",
      "step:476,train_loss:0.17521969974040985,train_acc:0.9352678656578064\n",
      "step:477,train_loss:0.18232916295528412,train_acc:0.9270833134651184\n",
      "step:478,train_loss:0.185555100440979,train_acc:0.9203869104385376\n",
      "step:479,train_loss:0.17983077466487885,train_acc:0.9278273582458496\n",
      "step:480,train_loss:0.18367740511894226,train_acc:0.925595223903656\n",
      "step:481,train_loss:0.1838805079460144,train_acc:0.925595223903656\n",
      "step:482,train_loss:0.1827578842639923,train_acc:0.9263392686843872\n",
      "step:483,train_loss:0.18029408156871796,train_acc:0.9278273582458496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:484,train_loss:0.17753519117832184,train_acc:0.9166666865348816\n",
      "step:485,train_loss:0.1648958921432495,train_acc:0.933779776096344\n",
      "step:486,train_loss:0.1696964055299759,train_acc:0.9345238208770752\n",
      "step:487,train_loss:0.17493736743927002,train_acc:0.9270833134651184\n",
      "step:488,train_loss:0.18844535946846008,train_acc:0.9203869104385376\n",
      "step:489,train_loss:0.16717574000358582,train_acc:0.9315476417541504\n",
      "step:490,train_loss:0.18042689561843872,train_acc:0.9211309552192688\n",
      "step:491,train_loss:0.17382952570915222,train_acc:0.933779776096344\n",
      "step:492,train_loss:0.17759323120117188,train_acc:0.930059552192688\n",
      "step:493,train_loss:0.1787613481283188,train_acc:0.9308035969734192\n",
      "step:494,train_loss:0.1744960993528366,train_acc:0.925595223903656\n",
      "step:495,train_loss:0.17289979755878448,train_acc:0.9278273582458496\n",
      "step:496,train_loss:0.1648693084716797,train_acc:0.930059552192688\n",
      "step:497,train_loss:0.17050407826900482,train_acc:0.930059552192688\n",
      "step:498,train_loss:0.16793020069599152,train_acc:0.933779776096344\n",
      "step:499,train_loss:0.193940669298172,train_acc:0.9211309552192688\n",
      "step:500,train_loss:0.18435370922088623,train_acc:0.925595223903656\n",
      "val_acc:0.9293154875437418\n",
      "step:501,train_loss:0.17483754456043243,train_acc:0.930059552192688\n",
      "step:502,train_loss:0.17052030563354492,train_acc:0.9315476417541504\n",
      "step:503,train_loss:0.1900843232870102,train_acc:0.9188988208770752\n",
      "step:504,train_loss:0.18271228671073914,train_acc:0.9270833134651184\n",
      "step:505,train_loss:0.19359762966632843,train_acc:0.9084821343421936\n",
      "step:506,train_loss:0.1533452570438385,train_acc:0.9464285969734192\n",
      "step:507,train_loss:0.16715291142463684,train_acc:0.9315476417541504\n",
      "step:508,train_loss:0.15339022874832153,train_acc:0.9389880895614624\n",
      "step:509,train_loss:0.17019037902355194,train_acc:0.9270833134651184\n",
      "step:510,train_loss:0.16954833269119263,train_acc:0.9397321343421936\n",
      "step:511,train_loss:0.17857694625854492,train_acc:0.9241071343421936\n",
      "step:512,train_loss:0.16773445904254913,train_acc:0.933779776096344\n",
      "step:513,train_loss:0.15888527035713196,train_acc:0.941220223903656\n",
      "step:514,train_loss:0.15626581013202667,train_acc:0.9382440447807312\n",
      "step:515,train_loss:0.17479665577411652,train_acc:0.9270833134651184\n",
      "step:516,train_loss:0.17587052285671234,train_acc:0.9315476417541504\n",
      "step:517,train_loss:0.1919879913330078,train_acc:0.9174107313156128\n",
      "step:518,train_loss:0.15934596955776215,train_acc:0.9375\n",
      "step:519,train_loss:0.16934427618980408,train_acc:0.9345238208770752\n",
      "step:520,train_loss:0.16639643907546997,train_acc:0.9330357313156128\n",
      "step:521,train_loss:0.16633222997188568,train_acc:0.9345238208770752\n",
      "step:522,train_loss:0.17086021602153778,train_acc:0.9330357313156128\n",
      "step:523,train_loss:0.15881651639938354,train_acc:0.9367559552192688\n",
      "step:524,train_loss:0.17949984967708588,train_acc:0.925595223903656\n",
      "step:525,train_loss:0.16601154208183289,train_acc:0.930059552192688\n",
      "step:526,train_loss:0.16162225604057312,train_acc:0.9345238208770752\n",
      "step:527,train_loss:0.15622234344482422,train_acc:0.9375\n",
      "step:528,train_loss:0.16956710815429688,train_acc:0.9382440447807312\n",
      "step:529,train_loss:0.18478389084339142,train_acc:0.9211309552192688\n",
      "step:530,train_loss:0.16108907759189606,train_acc:0.933779776096344\n",
      "step:531,train_loss:0.16321617364883423,train_acc:0.933779776096344\n",
      "step:532,train_loss:0.16396580636501312,train_acc:0.941220223903656\n",
      "step:533,train_loss:0.15570642054080963,train_acc:0.9367559552192688\n",
      "step:534,train_loss:0.1598644256591797,train_acc:0.9285714030265808\n",
      "step:535,train_loss:0.16616332530975342,train_acc:0.9330357313156128\n",
      "step:536,train_loss:0.1354430913925171,train_acc:0.9508928656578064\n",
      "step:537,train_loss:0.15246836841106415,train_acc:0.9404761791229248\n",
      "step:538,train_loss:0.1662142425775528,train_acc:0.9375\n",
      "step:539,train_loss:0.1608867347240448,train_acc:0.933779776096344\n",
      "step:540,train_loss:0.17552602291107178,train_acc:0.930059552192688\n",
      "step:541,train_loss:0.16691872477531433,train_acc:0.929315447807312\n",
      "step:542,train_loss:0.1518106758594513,train_acc:0.945684552192688\n",
      "step:543,train_loss:0.15594464540481567,train_acc:0.945684552192688\n",
      "step:544,train_loss:0.15530382096767426,train_acc:0.9397321343421936\n",
      "step:545,train_loss:0.1514313519001007,train_acc:0.9419642686843872\n",
      "step:546,train_loss:0.13438649475574493,train_acc:0.956845223903656\n",
      "step:547,train_loss:0.1708095371723175,train_acc:0.9345238208770752\n",
      "step:548,train_loss:0.14506882429122925,train_acc:0.949404776096344\n",
      "step:549,train_loss:0.1567656397819519,train_acc:0.941220223903656\n",
      "step:550,train_loss:0.1743994951248169,train_acc:0.9248511791229248\n",
      "val_acc:0.9394841392834982\n",
      "step:551,train_loss:0.16916696727275848,train_acc:0.9308035969734192\n",
      "step:552,train_loss:0.15879349410533905,train_acc:0.9375\n",
      "step:553,train_loss:0.1765967458486557,train_acc:0.9278273582458496\n",
      "step:554,train_loss:0.14653562009334564,train_acc:0.9419642686843872\n",
      "step:555,train_loss:0.1584089994430542,train_acc:0.9404761791229248\n",
      "step:556,train_loss:0.15950286388397217,train_acc:0.9360119104385376\n",
      "step:557,train_loss:0.14852216839790344,train_acc:0.9441964030265808\n",
      "step:558,train_loss:0.16312147676944733,train_acc:0.9352678656578064\n",
      "step:559,train_loss:0.14212654531002045,train_acc:0.944940447807312\n",
      "step:560,train_loss:0.16223080456256866,train_acc:0.9375\n",
      "step:561,train_loss:0.1704898625612259,train_acc:0.9360119104385376\n",
      "step:562,train_loss:0.15499484539031982,train_acc:0.9322916865348816\n",
      "step:563,train_loss:0.1495015025138855,train_acc:0.9434523582458496\n",
      "step:564,train_loss:0.1410166472196579,train_acc:0.9441964030265808\n",
      "step:565,train_loss:0.14442965388298035,train_acc:0.9479166865348816\n",
      "step:566,train_loss:0.1548546850681305,train_acc:0.933779776096344\n",
      "step:567,train_loss:0.14742600917816162,train_acc:0.9441964030265808\n",
      "step:568,train_loss:0.15398868918418884,train_acc:0.9382440447807312\n",
      "step:569,train_loss:0.13407523930072784,train_acc:0.9508928656578064\n",
      "step:570,train_loss:0.13826040923595428,train_acc:0.949404776096344\n",
      "step:571,train_loss:0.14846576750278473,train_acc:0.9397321343421936\n",
      "step:572,train_loss:0.15969707071781158,train_acc:0.9330357313156128\n",
      "step:573,train_loss:0.169658824801445,train_acc:0.9360119104385376\n",
      "step:574,train_loss:0.15964442491531372,train_acc:0.9345238208770752\n",
      "step:575,train_loss:0.146633118391037,train_acc:0.944940447807312\n",
      "step:576,train_loss:0.15265046060085297,train_acc:0.944940447807312\n",
      "step:577,train_loss:0.1368650645017624,train_acc:0.9590773582458496\n",
      "step:578,train_loss:0.1348525732755661,train_acc:0.9464285969734192\n",
      "step:579,train_loss:0.17204055190086365,train_acc:0.930059552192688\n",
      "step:580,train_loss:0.1307351291179657,train_acc:0.9561011791229248\n",
      "step:581,train_loss:0.13339412212371826,train_acc:0.949404776096344\n",
      "step:582,train_loss:0.15948402881622314,train_acc:0.9375\n",
      "step:583,train_loss:0.12854766845703125,train_acc:0.9590773582458496\n",
      "step:584,train_loss:0.1568262130022049,train_acc:0.9352678656578064\n",
      "step:585,train_loss:0.14701659977436066,train_acc:0.9441964030265808\n",
      "step:586,train_loss:0.13587027788162231,train_acc:0.9516369104385376\n",
      "step:587,train_loss:0.13675785064697266,train_acc:0.9546130895614624\n",
      "step:588,train_loss:0.14738677442073822,train_acc:0.9419642686843872\n",
      "step:589,train_loss:0.14401943981647491,train_acc:0.9486607313156128\n",
      "step:590,train_loss:0.14289095997810364,train_acc:0.9464285969734192\n",
      "step:591,train_loss:0.1349148005247116,train_acc:0.9538690447807312\n",
      "step:592,train_loss:0.13072256743907928,train_acc:0.956845223903656\n",
      "step:593,train_loss:0.13355527818202972,train_acc:0.949404776096344\n",
      "step:594,train_loss:0.11526069045066833,train_acc:0.9583333134651184\n",
      "step:595,train_loss:0.12328442931175232,train_acc:0.9561011791229248\n",
      "step:596,train_loss:0.12843027710914612,train_acc:0.9508928656578064\n",
      "step:597,train_loss:0.14283046126365662,train_acc:0.9464285969734192\n",
      "step:598,train_loss:0.15129859745502472,train_acc:0.9352678656578064\n",
      "step:599,train_loss:0.15496499836444855,train_acc:0.9360119104385376\n",
      "step:600,train_loss:0.1310509294271469,train_acc:0.9561011791229248\n",
      "val_acc:0.9496527711550394\n",
      "step:601,train_loss:0.12941047549247742,train_acc:0.944940447807312\n",
      "step:602,train_loss:0.12176953256130219,train_acc:0.9575892686843872\n",
      "step:603,train_loss:0.15047529339790344,train_acc:0.941220223903656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:604,train_loss:0.1303161382675171,train_acc:0.953125\n",
      "step:605,train_loss:0.12716765701770782,train_acc:0.956845223903656\n",
      "step:606,train_loss:0.13409817218780518,train_acc:0.953125\n",
      "step:607,train_loss:0.13940906524658203,train_acc:0.944940447807312\n",
      "step:608,train_loss:0.1268918663263321,train_acc:0.953125\n",
      "step:609,train_loss:0.17555320262908936,train_acc:0.9270833134651184\n",
      "step:610,train_loss:0.16289176046848297,train_acc:0.9382440447807312\n",
      "step:611,train_loss:0.15214839577674866,train_acc:0.9389880895614624\n",
      "step:612,train_loss:0.135188028216362,train_acc:0.9508928656578064\n",
      "step:613,train_loss:0.13895630836486816,train_acc:0.945684552192688\n",
      "step:614,train_loss:0.13265112042427063,train_acc:0.9471726417541504\n",
      "step:615,train_loss:0.1374533623456955,train_acc:0.944940447807312\n",
      "step:616,train_loss:0.13266074657440186,train_acc:0.9508928656578064\n",
      "step:617,train_loss:0.1358392834663391,train_acc:0.9501488208770752\n",
      "step:618,train_loss:0.12948459386825562,train_acc:0.9508928656578064\n",
      "step:619,train_loss:0.13829366862773895,train_acc:0.9434523582458496\n",
      "step:620,train_loss:0.12319749593734741,train_acc:0.9538690447807312\n",
      "step:621,train_loss:0.12577016651630402,train_acc:0.9561011791229248\n",
      "step:622,train_loss:0.14691504836082458,train_acc:0.9367559552192688\n",
      "step:623,train_loss:0.13930733501911163,train_acc:0.9486607313156128\n",
      "step:624,train_loss:0.11927706748247147,train_acc:0.9575892686843872\n",
      "step:625,train_loss:0.18616044521331787,train_acc:0.9159226417541504\n",
      "step:626,train_loss:0.13758672773838043,train_acc:0.9427083134651184\n",
      "step:627,train_loss:0.11798516660928726,train_acc:0.9553571343421936\n",
      "step:628,train_loss:0.14772288501262665,train_acc:0.9382440447807312\n",
      "step:629,train_loss:0.13893279433250427,train_acc:0.941220223903656\n",
      "step:630,train_loss:0.1431361883878708,train_acc:0.945684552192688\n",
      "step:631,train_loss:0.12411051988601685,train_acc:0.9561011791229248\n",
      "step:632,train_loss:0.14115580916404724,train_acc:0.944940447807312\n",
      "step:633,train_loss:0.13661496341228485,train_acc:0.945684552192688\n",
      "step:634,train_loss:0.10961941629648209,train_acc:0.9680059552192688\n",
      "step:635,train_loss:0.14077427983283997,train_acc:0.9434523582458496\n",
      "step:636,train_loss:0.1325254887342453,train_acc:0.9479166865348816\n",
      "step:637,train_loss:0.12814919650554657,train_acc:0.9523809552192688\n",
      "step:638,train_loss:0.16170518100261688,train_acc:0.930059552192688\n",
      "step:639,train_loss:0.12507972121238708,train_acc:0.9486607313156128\n",
      "step:640,train_loss:0.1285357028245926,train_acc:0.953125\n",
      "step:641,train_loss:0.1420595943927765,train_acc:0.9441964030265808\n",
      "step:642,train_loss:0.12855017185211182,train_acc:0.949404776096344\n",
      "step:643,train_loss:0.13815784454345703,train_acc:0.944940447807312\n",
      "step:644,train_loss:0.13448402285575867,train_acc:0.9501488208770752\n",
      "step:645,train_loss:0.11227601766586304,train_acc:0.9635416865348816\n",
      "step:646,train_loss:0.12066856771707535,train_acc:0.9598214030265808\n",
      "step:647,train_loss:0.1274089366197586,train_acc:0.9553571343421936\n",
      "step:648,train_loss:0.1334550678730011,train_acc:0.9479166865348816\n",
      "step:649,train_loss:0.12332432717084885,train_acc:0.9561011791229248\n",
      "step:650,train_loss:0.10895345360040665,train_acc:0.9657738208770752\n",
      "val_acc:0.954365074634552\n",
      "step:651,train_loss:0.1345032900571823,train_acc:0.9516369104385376\n",
      "step:652,train_loss:0.12191461026668549,train_acc:0.9561011791229248\n",
      "step:653,train_loss:0.12278645485639572,train_acc:0.9538690447807312\n",
      "step:654,train_loss:0.10419559478759766,train_acc:0.9657738208770752\n",
      "step:655,train_loss:0.1321558952331543,train_acc:0.9471726417541504\n",
      "step:656,train_loss:0.1264095902442932,train_acc:0.949404776096344\n",
      "step:657,train_loss:0.12737014889717102,train_acc:0.9561011791229248\n",
      "step:658,train_loss:0.14197155833244324,train_acc:0.9404761791229248\n",
      "step:659,train_loss:0.14323070645332336,train_acc:0.9486607313156128\n",
      "step:660,train_loss:0.11855613440275192,train_acc:0.949404776096344\n",
      "step:661,train_loss:0.12455324828624725,train_acc:0.9508928656578064\n",
      "step:662,train_loss:0.11949259787797928,train_acc:0.9546130895614624\n",
      "step:663,train_loss:0.13474395871162415,train_acc:0.9479166865348816\n",
      "step:664,train_loss:0.11347046494483948,train_acc:0.960565447807312\n",
      "step:665,train_loss:0.11206086724996567,train_acc:0.961309552192688\n",
      "step:666,train_loss:0.11197090148925781,train_acc:0.9583333134651184\n",
      "step:667,train_loss:0.14212171733379364,train_acc:0.9382440447807312\n",
      "step:668,train_loss:0.1225915178656578,train_acc:0.9501488208770752\n",
      "step:669,train_loss:0.12130708992481232,train_acc:0.9523809552192688\n",
      "step:670,train_loss:0.14701783657073975,train_acc:0.9389880895614624\n",
      "step:671,train_loss:0.11874257773160934,train_acc:0.956845223903656\n",
      "step:672,train_loss:0.11664308607578278,train_acc:0.956845223903656\n",
      "step:673,train_loss:0.11284184455871582,train_acc:0.9553571343421936\n",
      "step:674,train_loss:0.11249642074108124,train_acc:0.960565447807312\n",
      "step:675,train_loss:0.10846225172281265,train_acc:0.9627976417541504\n",
      "step:676,train_loss:0.12956950068473816,train_acc:0.9561011791229248\n",
      "step:677,train_loss:0.11140047013759613,train_acc:0.965029776096344\n",
      "step:678,train_loss:0.11013498902320862,train_acc:0.9635416865348816\n",
      "step:679,train_loss:0.11371000856161118,train_acc:0.9598214030265808\n",
      "step:680,train_loss:0.12056702375411987,train_acc:0.9546130895614624\n",
      "step:681,train_loss:0.11536585539579391,train_acc:0.9598214030265808\n",
      "step:682,train_loss:0.10376535356044769,train_acc:0.9672619104385376\n",
      "step:683,train_loss:0.12041178345680237,train_acc:0.9583333134651184\n",
      "step:684,train_loss:0.12400603294372559,train_acc:0.9501488208770752\n",
      "step:685,train_loss:0.15273301303386688,train_acc:0.9345238208770752\n",
      "step:686,train_loss:0.12641140818595886,train_acc:0.953125\n",
      "step:687,train_loss:0.1276169717311859,train_acc:0.9479166865348816\n",
      "step:688,train_loss:0.1200425997376442,train_acc:0.9583333134651184\n",
      "step:689,train_loss:0.11438514292240143,train_acc:0.9627976417541504\n",
      "step:690,train_loss:0.10818958282470703,train_acc:0.9575892686843872\n",
      "step:691,train_loss:0.12009507417678833,train_acc:0.9575892686843872\n",
      "step:692,train_loss:0.13562995195388794,train_acc:0.9501488208770752\n",
      "step:693,train_loss:0.11296354979276657,train_acc:0.9620535969734192\n",
      "step:694,train_loss:0.12142108380794525,train_acc:0.9546130895614624\n",
      "step:695,train_loss:0.13411182165145874,train_acc:0.9464285969734192\n",
      "step:696,train_loss:0.10267622023820877,train_acc:0.9657738208770752\n",
      "step:697,train_loss:0.11784754693508148,train_acc:0.956845223903656\n",
      "step:698,train_loss:0.11357582360506058,train_acc:0.9538690447807312\n",
      "step:699,train_loss:0.10974927246570587,train_acc:0.9657738208770752\n",
      "step:700,train_loss:0.11777466535568237,train_acc:0.9583333134651184\n",
      "val_acc:0.9660218159357706\n",
      "step:701,train_loss:0.10492656379938126,train_acc:0.9627976417541504\n",
      "step:702,train_loss:0.10894252359867096,train_acc:0.9598214030265808\n",
      "step:703,train_loss:0.11016713827848434,train_acc:0.9590773582458496\n",
      "step:704,train_loss:0.10295416414737701,train_acc:0.965029776096344\n",
      "step:705,train_loss:0.10625668615102768,train_acc:0.9672619104385376\n",
      "step:706,train_loss:0.11803837865591049,train_acc:0.9501488208770752\n",
      "step:707,train_loss:0.10558375716209412,train_acc:0.9642857313156128\n",
      "step:708,train_loss:0.09305822104215622,train_acc:0.9732142686843872\n",
      "step:709,train_loss:0.08817750960588455,train_acc:0.972470223903656\n",
      "step:710,train_loss:0.09647885710000992,train_acc:0.9665178656578064\n",
      "step:711,train_loss:0.11992235481739044,train_acc:0.9538690447807312\n",
      "step:712,train_loss:0.12915274500846863,train_acc:0.949404776096344\n",
      "step:713,train_loss:0.12693221867084503,train_acc:0.9523809552192688\n",
      "step:714,train_loss:0.10968050360679626,train_acc:0.9598214030265808\n",
      "step:715,train_loss:0.10593686997890472,train_acc:0.9672619104385376\n",
      "step:716,train_loss:0.10863946378231049,train_acc:0.965029776096344\n",
      "step:717,train_loss:0.12866227328777313,train_acc:0.953125\n",
      "step:718,train_loss:0.12100998312234879,train_acc:0.9516369104385376\n",
      "step:719,train_loss:0.1182783991098404,train_acc:0.9538690447807312\n",
      "step:720,train_loss:0.10683957487344742,train_acc:0.961309552192688\n",
      "step:721,train_loss:0.10736484825611115,train_acc:0.9635416865348816\n",
      "step:722,train_loss:0.1207561045885086,train_acc:0.9516369104385376\n",
      "step:723,train_loss:0.11034560203552246,train_acc:0.9561011791229248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:724,train_loss:0.12295695394277573,train_acc:0.9538690447807312\n",
      "step:725,train_loss:0.13864102959632874,train_acc:0.9434523582458496\n",
      "step:726,train_loss:0.11637689918279648,train_acc:0.9665178656578064\n",
      "step:727,train_loss:0.11218231171369553,train_acc:0.961309552192688\n",
      "step:728,train_loss:0.12774354219436646,train_acc:0.9501488208770752\n",
      "step:729,train_loss:0.1167440414428711,train_acc:0.9598214030265808\n",
      "step:730,train_loss:0.09508804976940155,train_acc:0.9739583134651184\n",
      "step:731,train_loss:0.10169774293899536,train_acc:0.965029776096344\n",
      "step:732,train_loss:0.11076441407203674,train_acc:0.9598214030265808\n",
      "step:733,train_loss:0.10215076059103012,train_acc:0.965029776096344\n",
      "step:734,train_loss:0.10766744613647461,train_acc:0.961309552192688\n",
      "step:735,train_loss:0.0992734283208847,train_acc:0.9620535969734192\n",
      "step:736,train_loss:0.08550027757883072,train_acc:0.976190447807312\n",
      "step:737,train_loss:0.13686391711235046,train_acc:0.941220223903656\n",
      "step:738,train_loss:0.10833016037940979,train_acc:0.9627976417541504\n",
      "step:739,train_loss:0.1054844856262207,train_acc:0.9627976417541504\n",
      "step:740,train_loss:0.10116882622241974,train_acc:0.9672619104385376\n",
      "step:741,train_loss:0.10774553567171097,train_acc:0.960565447807312\n",
      "step:742,train_loss:0.12220782041549683,train_acc:0.956845223903656\n",
      "step:743,train_loss:0.0855376273393631,train_acc:0.972470223903656\n",
      "step:744,train_loss:0.09418642520904541,train_acc:0.972470223903656\n",
      "step:745,train_loss:0.10050594061613083,train_acc:0.965029776096344\n",
      "step:746,train_loss:0.10262177884578705,train_acc:0.9680059552192688\n",
      "step:747,train_loss:0.08456853777170181,train_acc:0.9732142686843872\n",
      "step:748,train_loss:0.10413385927677155,train_acc:0.965029776096344\n",
      "step:749,train_loss:0.11302263289690018,train_acc:0.9598214030265808\n",
      "step:750,train_loss:0.08392931520938873,train_acc:0.980654776096344\n",
      "val_acc:0.9766865173975626\n",
      "step:751,train_loss:0.09894541651010513,train_acc:0.9694940447807312\n",
      "step:752,train_loss:0.11258244514465332,train_acc:0.9598214030265808\n",
      "step:753,train_loss:0.11620771139860153,train_acc:0.953125\n",
      "step:754,train_loss:0.10146492719650269,train_acc:0.96875\n",
      "step:755,train_loss:0.12052501738071442,train_acc:0.9546130895614624\n",
      "step:756,train_loss:0.11033177375793457,train_acc:0.9590773582458496\n",
      "step:757,train_loss:0.10510208457708359,train_acc:0.9620535969734192\n",
      "step:758,train_loss:0.09538045525550842,train_acc:0.9627976417541504\n",
      "step:759,train_loss:0.09891249239444733,train_acc:0.9665178656578064\n",
      "step:760,train_loss:0.10355222970247269,train_acc:0.9627976417541504\n",
      "step:761,train_loss:0.11845120042562485,train_acc:0.9523809552192688\n",
      "step:762,train_loss:0.09240952879190445,train_acc:0.972470223903656\n",
      "step:763,train_loss:0.09090884029865265,train_acc:0.9747023582458496\n",
      "step:764,train_loss:0.1181364431977272,train_acc:0.9523809552192688\n",
      "step:765,train_loss:0.09566100686788559,train_acc:0.961309552192688\n",
      "step:766,train_loss:0.08436330407857895,train_acc:0.9717261791229248\n",
      "step:767,train_loss:0.09899641573429108,train_acc:0.9635416865348816\n",
      "step:768,train_loss:0.10649324953556061,train_acc:0.9635416865348816\n",
      "step:769,train_loss:0.08408407121896744,train_acc:0.976190447807312\n",
      "step:770,train_loss:0.1000724658370018,train_acc:0.965029776096344\n",
      "step:771,train_loss:0.08681300282478333,train_acc:0.9709821343421936\n",
      "step:772,train_loss:0.1097947284579277,train_acc:0.9583333134651184\n",
      "step:773,train_loss:0.09688637405633926,train_acc:0.9642857313156128\n",
      "step:774,train_loss:0.09413889795541763,train_acc:0.9665178656578064\n",
      "step:775,train_loss:0.09524965286254883,train_acc:0.96875\n",
      "step:776,train_loss:0.09372899681329727,train_acc:0.9702380895614624\n",
      "step:777,train_loss:0.08745364844799042,train_acc:0.972470223903656\n",
      "step:778,train_loss:0.10246697068214417,train_acc:0.9657738208770752\n",
      "step:779,train_loss:0.09877417981624603,train_acc:0.9665178656578064\n",
      "step:780,train_loss:0.09429680556058884,train_acc:0.9665178656578064\n",
      "step:781,train_loss:0.11079529672861099,train_acc:0.9598214030265808\n",
      "step:782,train_loss:0.10631765425205231,train_acc:0.9657738208770752\n",
      "step:783,train_loss:0.11201824247837067,train_acc:0.956845223903656\n",
      "step:784,train_loss:0.09322357177734375,train_acc:0.9694940447807312\n",
      "step:785,train_loss:0.10604158788919449,train_acc:0.9598214030265808\n",
      "step:786,train_loss:0.10136166214942932,train_acc:0.9635416865348816\n",
      "step:787,train_loss:0.10799873620271683,train_acc:0.9635416865348816\n",
      "step:788,train_loss:0.0945829451084137,train_acc:0.9694940447807312\n",
      "step:789,train_loss:0.09264533966779709,train_acc:0.9709821343421936\n",
      "step:790,train_loss:0.09807933866977692,train_acc:0.9590773582458496\n",
      "step:791,train_loss:0.09402447938919067,train_acc:0.9702380895614624\n",
      "step:792,train_loss:0.09739871323108673,train_acc:0.9627976417541504\n",
      "step:793,train_loss:0.09360253065824509,train_acc:0.9702380895614624\n",
      "step:794,train_loss:0.09161658585071564,train_acc:0.96875\n",
      "step:795,train_loss:0.10004633665084839,train_acc:0.9627976417541504\n",
      "step:796,train_loss:0.12155932188034058,train_acc:0.9561011791229248\n",
      "step:797,train_loss:0.09216920286417007,train_acc:0.9672619104385376\n",
      "step:798,train_loss:0.10795239359140396,train_acc:0.9590773582458496\n",
      "step:799,train_loss:0.09497912973165512,train_acc:0.9717261791229248\n",
      "step:800,train_loss:0.09654325246810913,train_acc:0.9627976417541504\n",
      "val_acc:0.9627976020177206\n",
      "step:801,train_loss:0.08869994431734085,train_acc:0.9680059552192688\n",
      "step:802,train_loss:0.11140932142734528,train_acc:0.9553571343421936\n",
      "step:803,train_loss:0.10205529630184174,train_acc:0.9635416865348816\n",
      "step:804,train_loss:0.08348413556814194,train_acc:0.96875\n",
      "step:805,train_loss:0.0978226512670517,train_acc:0.9657738208770752\n",
      "step:806,train_loss:0.09249305725097656,train_acc:0.9665178656578064\n",
      "step:807,train_loss:0.10844235122203827,train_acc:0.9590773582458496\n",
      "step:808,train_loss:0.11144048720598221,train_acc:0.9538690447807312\n",
      "step:809,train_loss:0.09227918088436127,train_acc:0.9709821343421936\n",
      "step:810,train_loss:0.08714506775140762,train_acc:0.976934552192688\n",
      "step:811,train_loss:0.10780754685401917,train_acc:0.9627976417541504\n",
      "step:812,train_loss:0.09744344651699066,train_acc:0.9672619104385376\n",
      "step:813,train_loss:0.09962324798107147,train_acc:0.9709821343421936\n",
      "step:814,train_loss:0.08418601751327515,train_acc:0.9694940447807312\n",
      "step:815,train_loss:0.09819389879703522,train_acc:0.9620535969734192\n",
      "step:816,train_loss:0.09066697210073471,train_acc:0.9702380895614624\n",
      "step:817,train_loss:0.07540681958198547,train_acc:0.9776785969734192\n",
      "step:818,train_loss:0.07330092042684555,train_acc:0.9791666865348816\n",
      "step:819,train_loss:0.08600229024887085,train_acc:0.9665178656578064\n",
      "step:820,train_loss:0.07827699929475784,train_acc:0.9739583134651184\n",
      "step:821,train_loss:0.08067898452281952,train_acc:0.9784226417541504\n",
      "step:822,train_loss:0.08747393637895584,train_acc:0.972470223903656\n",
      "step:823,train_loss:0.07999123632907867,train_acc:0.9747023582458496\n",
      "step:824,train_loss:0.08343067765235901,train_acc:0.9694940447807312\n",
      "step:825,train_loss:0.10863340646028519,train_acc:0.9553571343421936\n",
      "step:826,train_loss:0.09930256754159927,train_acc:0.9635416865348816\n",
      "step:827,train_loss:0.11062788963317871,train_acc:0.9642857313156128\n",
      "step:828,train_loss:0.0842810794711113,train_acc:0.96875\n",
      "step:829,train_loss:0.09084773063659668,train_acc:0.96875\n",
      "step:830,train_loss:0.09298142045736313,train_acc:0.9709821343421936\n",
      "step:831,train_loss:0.07392319291830063,train_acc:0.9791666865348816\n",
      "step:832,train_loss:0.09960851073265076,train_acc:0.9665178656578064\n",
      "step:833,train_loss:0.08655866235494614,train_acc:0.976190447807312\n",
      "step:834,train_loss:0.08859462291002274,train_acc:0.9739583134651184\n",
      "step:835,train_loss:0.07279843837022781,train_acc:0.980654776096344\n",
      "step:836,train_loss:0.08996482193470001,train_acc:0.9665178656578064\n",
      "step:837,train_loss:0.10698897391557693,train_acc:0.961309552192688\n",
      "step:838,train_loss:0.07177921384572983,train_acc:0.9799107313156128\n",
      "step:839,train_loss:0.0956626832485199,train_acc:0.9665178656578064\n",
      "step:840,train_loss:0.08221925795078278,train_acc:0.9665178656578064\n",
      "step:841,train_loss:0.0800408199429512,train_acc:0.9754464030265808\n",
      "step:842,train_loss:0.07616996020078659,train_acc:0.9799107313156128\n",
      "step:843,train_loss:0.07934579998254776,train_acc:0.9739583134651184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:844,train_loss:0.08503526449203491,train_acc:0.976190447807312\n",
      "step:845,train_loss:0.08292137086391449,train_acc:0.9694940447807312\n",
      "step:846,train_loss:0.0807657465338707,train_acc:0.976190447807312\n",
      "step:847,train_loss:0.07723560184240341,train_acc:0.9702380895614624\n",
      "step:848,train_loss:0.08190452307462692,train_acc:0.976934552192688\n",
      "step:849,train_loss:0.07829280942678452,train_acc:0.9754464030265808\n",
      "step:850,train_loss:0.07715055346488953,train_acc:0.9717261791229248\n",
      "val_acc:0.973710298538208\n",
      "step:851,train_loss:0.07127265632152557,train_acc:0.9776785969734192\n",
      "step:852,train_loss:0.06571976095438004,train_acc:0.984375\n",
      "step:853,train_loss:0.08912717550992966,train_acc:0.9732142686843872\n",
      "step:854,train_loss:0.0648961067199707,train_acc:0.9813988208770752\n",
      "step:855,train_loss:0.08931643515825272,train_acc:0.9754464030265808\n",
      "step:856,train_loss:0.07425445318222046,train_acc:0.9754464030265808\n",
      "step:857,train_loss:0.07775197923183441,train_acc:0.9739583134651184\n",
      "step:858,train_loss:0.09111249446868896,train_acc:0.9732142686843872\n",
      "step:859,train_loss:0.06624525785446167,train_acc:0.9813988208770752\n",
      "step:860,train_loss:0.07272211462259293,train_acc:0.9821428656578064\n",
      "step:861,train_loss:0.09275224059820175,train_acc:0.965029776096344\n",
      "step:862,train_loss:0.07880064100027084,train_acc:0.9799107313156128\n",
      "step:863,train_loss:0.07839824259281158,train_acc:0.976190447807312\n",
      "step:864,train_loss:0.09130337089300156,train_acc:0.9665178656578064\n",
      "step:865,train_loss:0.09419550001621246,train_acc:0.9672619104385376\n",
      "step:866,train_loss:0.0744590014219284,train_acc:0.9747023582458496\n",
      "step:867,train_loss:0.09303485602140427,train_acc:0.9620535969734192\n",
      "step:868,train_loss:0.09255814552307129,train_acc:0.9702380895614624\n",
      "step:869,train_loss:0.07628148049116135,train_acc:0.976190447807312\n",
      "step:870,train_loss:0.07804913818836212,train_acc:0.9732142686843872\n",
      "step:871,train_loss:0.07549754530191422,train_acc:0.9717261791229248\n",
      "step:872,train_loss:0.07327442616224289,train_acc:0.976934552192688\n",
      "step:873,train_loss:0.07365375757217407,train_acc:0.9776785969734192\n",
      "step:874,train_loss:0.06075761839747429,train_acc:0.9821428656578064\n",
      "step:875,train_loss:0.0790782943367958,train_acc:0.9747023582458496\n",
      "step:876,train_loss:0.07318279892206192,train_acc:0.9747023582458496\n",
      "step:877,train_loss:0.07679788768291473,train_acc:0.9776785969734192\n",
      "step:878,train_loss:0.05666101723909378,train_acc:0.9888392686843872\n",
      "step:879,train_loss:0.07261873036623001,train_acc:0.980654776096344\n",
      "step:880,train_loss:0.06490316987037659,train_acc:0.9828869104385376\n",
      "step:881,train_loss:0.07552574574947357,train_acc:0.9754464030265808\n",
      "step:882,train_loss:0.07841853052377701,train_acc:0.980654776096344\n",
      "step:883,train_loss:0.07684903591871262,train_acc:0.9739583134651184\n",
      "step:884,train_loss:0.07782615721225739,train_acc:0.972470223903656\n",
      "step:885,train_loss:0.07920187711715698,train_acc:0.9702380895614624\n",
      "step:886,train_loss:0.06664446741342545,train_acc:0.9851190447807312\n",
      "step:887,train_loss:0.07863801717758179,train_acc:0.9709821343421936\n",
      "step:888,train_loss:0.06915391981601715,train_acc:0.976934552192688\n",
      "step:889,train_loss:0.08595945686101913,train_acc:0.9709821343421936\n",
      "step:890,train_loss:0.07745814323425293,train_acc:0.976190447807312\n",
      "step:891,train_loss:0.0678907260298729,train_acc:0.9784226417541504\n",
      "step:892,train_loss:0.068778857588768,train_acc:0.9799107313156128\n",
      "step:893,train_loss:0.07716678082942963,train_acc:0.9747023582458496\n",
      "step:894,train_loss:0.07709835469722748,train_acc:0.9732142686843872\n",
      "step:895,train_loss:0.06846088171005249,train_acc:0.9828869104385376\n",
      "step:896,train_loss:0.0746634379029274,train_acc:0.9747023582458496\n",
      "step:897,train_loss:0.08300785720348358,train_acc:0.965029776096344\n",
      "step:898,train_loss:0.06831178069114685,train_acc:0.976934552192688\n",
      "step:899,train_loss:0.0718645229935646,train_acc:0.976934552192688\n",
      "step:900,train_loss:0.05181186646223068,train_acc:0.988095223903656\n",
      "val_acc:0.9866071343421936\n",
      "step:901,train_loss:0.07801055163145065,train_acc:0.9732142686843872\n",
      "step:902,train_loss:0.08292180299758911,train_acc:0.9680059552192688\n",
      "step:903,train_loss:0.06618920713663101,train_acc:0.9828869104385376\n",
      "step:904,train_loss:0.0679745301604271,train_acc:0.9791666865348816\n",
      "step:905,train_loss:0.07668396085500717,train_acc:0.9799107313156128\n",
      "step:906,train_loss:0.06215257942676544,train_acc:0.980654776096344\n",
      "step:907,train_loss:0.06150534003973007,train_acc:0.9836309552192688\n",
      "step:908,train_loss:0.06516801565885544,train_acc:0.980654776096344\n",
      "step:909,train_loss:0.06660790741443634,train_acc:0.984375\n",
      "step:910,train_loss:0.06822570413351059,train_acc:0.9813988208770752\n",
      "step:911,train_loss:0.06321336328983307,train_acc:0.984375\n",
      "step:912,train_loss:0.07601834833621979,train_acc:0.9747023582458496\n",
      "step:913,train_loss:0.07329928129911423,train_acc:0.9739583134651184\n",
      "step:914,train_loss:0.08224759995937347,train_acc:0.9717261791229248\n",
      "step:915,train_loss:0.07294932007789612,train_acc:0.9791666865348816\n",
      "step:916,train_loss:0.06612445414066315,train_acc:0.9791666865348816\n",
      "step:917,train_loss:0.07578710466623306,train_acc:0.9754464030265808\n",
      "step:918,train_loss:0.07304847240447998,train_acc:0.976190447807312\n",
      "step:919,train_loss:0.07606352865695953,train_acc:0.976190447807312\n",
      "step:920,train_loss:0.08518540114164352,train_acc:0.9642857313156128\n",
      "step:921,train_loss:0.07298360764980316,train_acc:0.972470223903656\n",
      "step:922,train_loss:0.0814601331949234,train_acc:0.9665178656578064\n",
      "step:923,train_loss:0.09039221704006195,train_acc:0.9702380895614624\n",
      "step:924,train_loss:0.07120148092508316,train_acc:0.9784226417541504\n",
      "step:925,train_loss:0.06705419719219208,train_acc:0.9799107313156128\n",
      "step:926,train_loss:0.059623368084430695,train_acc:0.9828869104385376\n",
      "step:927,train_loss:0.05929666385054588,train_acc:0.9836309552192688\n",
      "step:928,train_loss:0.07646214216947556,train_acc:0.972470223903656\n",
      "step:929,train_loss:0.063945472240448,train_acc:0.9821428656578064\n",
      "step:930,train_loss:0.0616089329123497,train_acc:0.984375\n",
      "step:931,train_loss:0.06466638296842575,train_acc:0.9821428656578064\n",
      "step:932,train_loss:0.09125714004039764,train_acc:0.9642857313156128\n",
      "step:933,train_loss:0.08161288499832153,train_acc:0.9709821343421936\n",
      "step:934,train_loss:0.07297764718532562,train_acc:0.9739583134651184\n",
      "step:935,train_loss:0.0650981143116951,train_acc:0.9813988208770752\n",
      "step:936,train_loss:0.06826096773147583,train_acc:0.984375\n",
      "step:937,train_loss:0.0647292360663414,train_acc:0.9828869104385376\n",
      "step:938,train_loss:0.08211097121238708,train_acc:0.9709821343421936\n",
      "step:939,train_loss:0.06377266347408295,train_acc:0.980654776096344\n",
      "step:940,train_loss:0.045103512704372406,train_acc:0.9910714030265808\n",
      "step:941,train_loss:0.0697091817855835,train_acc:0.9784226417541504\n",
      "step:942,train_loss:0.05643424391746521,train_acc:0.988095223903656\n",
      "step:943,train_loss:0.07718127965927124,train_acc:0.9739583134651184\n",
      "step:944,train_loss:0.06874954700469971,train_acc:0.9791666865348816\n",
      "step:945,train_loss:0.08961929380893707,train_acc:0.96875\n",
      "step:946,train_loss:0.07657473534345627,train_acc:0.976190447807312\n",
      "step:947,train_loss:0.07266843318939209,train_acc:0.9739583134651184\n",
      "step:948,train_loss:0.064962238073349,train_acc:0.976190447807312\n",
      "step:949,train_loss:0.07373856753110886,train_acc:0.9784226417541504\n",
      "step:950,train_loss:0.08022791892290115,train_acc:0.9702380895614624\n",
      "val_acc:0.9858630895614624\n",
      "step:951,train_loss:0.07877475023269653,train_acc:0.972470223903656\n",
      "step:952,train_loss:0.05913155525922775,train_acc:0.984375\n",
      "step:953,train_loss:0.059393223375082016,train_acc:0.9866071343421936\n",
      "step:954,train_loss:0.06530623137950897,train_acc:0.9791666865348816\n",
      "step:955,train_loss:0.06072240322828293,train_acc:0.9836309552192688\n",
      "step:956,train_loss:0.05085710063576698,train_acc:0.9895833134651184\n",
      "step:957,train_loss:0.0677434653043747,train_acc:0.980654776096344\n",
      "step:958,train_loss:0.058010101318359375,train_acc:0.984375\n",
      "step:959,train_loss:0.07428623735904694,train_acc:0.976934552192688\n",
      "step:960,train_loss:0.07622802257537842,train_acc:0.9709821343421936\n",
      "step:961,train_loss:0.06664790213108063,train_acc:0.980654776096344\n",
      "step:962,train_loss:0.08230899274349213,train_acc:0.9694940447807312\n",
      "step:963,train_loss:0.07002154737710953,train_acc:0.976190447807312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:964,train_loss:0.07213562726974487,train_acc:0.976934552192688\n",
      "step:965,train_loss:0.07213625311851501,train_acc:0.9784226417541504\n",
      "step:966,train_loss:0.06472107023000717,train_acc:0.9784226417541504\n",
      "step:967,train_loss:0.06239554286003113,train_acc:0.9828869104385376\n",
      "step:968,train_loss:0.06848292052745819,train_acc:0.9776785969734192\n",
      "step:969,train_loss:0.06798513978719711,train_acc:0.9813988208770752\n",
      "step:970,train_loss:0.06071754917502403,train_acc:0.9799107313156128\n",
      "step:971,train_loss:0.060778744518756866,train_acc:0.9821428656578064\n",
      "step:972,train_loss:0.06771746277809143,train_acc:0.976934552192688\n",
      "step:973,train_loss:0.06044691056013107,train_acc:0.980654776096344\n",
      "step:974,train_loss:0.07014790177345276,train_acc:0.9799107313156128\n",
      "step:975,train_loss:0.0827917605638504,train_acc:0.9702380895614624\n",
      "step:976,train_loss:0.06975378096103668,train_acc:0.9784226417541504\n",
      "step:977,train_loss:0.0800234004855156,train_acc:0.9694940447807312\n",
      "step:978,train_loss:0.0543261356651783,train_acc:0.9858630895614624\n",
      "step:979,train_loss:0.07041405886411667,train_acc:0.9791666865348816\n",
      "step:980,train_loss:0.05523757264018059,train_acc:0.9888392686843872\n",
      "step:981,train_loss:0.09768518060445786,train_acc:0.9627976417541504\n",
      "step:982,train_loss:0.08671459555625916,train_acc:0.9672619104385376\n",
      "step:983,train_loss:0.06173771992325783,train_acc:0.984375\n",
      "step:984,train_loss:0.05926259234547615,train_acc:0.9873511791229248\n",
      "step:985,train_loss:0.0724659338593483,train_acc:0.9754464030265808\n",
      "step:986,train_loss:0.07165609300136566,train_acc:0.9747023582458496\n",
      "step:987,train_loss:0.05851659178733826,train_acc:0.9858630895614624\n",
      "step:988,train_loss:0.06200600787997246,train_acc:0.9776785969734192\n",
      "step:989,train_loss:0.08389459550380707,train_acc:0.965029776096344\n",
      "step:990,train_loss:0.08896669745445251,train_acc:0.9665178656578064\n",
      "step:991,train_loss:0.06203674152493477,train_acc:0.9821428656578064\n",
      "step:992,train_loss:0.05865512043237686,train_acc:0.984375\n",
      "step:993,train_loss:0.050868064165115356,train_acc:0.9873511791229248\n",
      "step:994,train_loss:0.0644567608833313,train_acc:0.9799107313156128\n",
      "step:995,train_loss:0.08009735494852066,train_acc:0.9717261791229248\n",
      "step:996,train_loss:0.04950374737381935,train_acc:0.9866071343421936\n",
      "step:997,train_loss:0.06986790895462036,train_acc:0.9747023582458496\n",
      "step:998,train_loss:0.06950628012418747,train_acc:0.9799107313156128\n",
      "step:999,train_loss:0.0586932972073555,train_acc:0.9799107313156128\n",
      "step:1000,train_loss:0.06847206503152847,train_acc:0.9821428656578064\n",
      "val_acc:0.9836309552192688\n",
      "step:1001,train_loss:0.07745469361543655,train_acc:0.9702380895614624\n",
      "step:1002,train_loss:0.09137575328350067,train_acc:0.9709821343421936\n",
      "step:1003,train_loss:0.06873579323291779,train_acc:0.9791666865348816\n",
      "step:1004,train_loss:0.08413738012313843,train_acc:0.9702380895614624\n",
      "step:1005,train_loss:0.06895026564598083,train_acc:0.9799107313156128\n",
      "step:1006,train_loss:0.07632242143154144,train_acc:0.9747023582458496\n",
      "step:1007,train_loss:0.052695922553539276,train_acc:0.9873511791229248\n",
      "step:1008,train_loss:0.06510118395090103,train_acc:0.980654776096344\n",
      "step:1009,train_loss:0.0720565989613533,train_acc:0.9784226417541504\n",
      "step:1010,train_loss:0.056525617837905884,train_acc:0.988095223903656\n",
      "step:1011,train_loss:0.05496913939714432,train_acc:0.9873511791229248\n",
      "step:1012,train_loss:0.054238852113485336,train_acc:0.9821428656578064\n",
      "step:1013,train_loss:0.05901095271110535,train_acc:0.9836309552192688\n",
      "step:1014,train_loss:0.05537095665931702,train_acc:0.9836309552192688\n",
      "step:1015,train_loss:0.059023402631282806,train_acc:0.9828869104385376\n",
      "step:1016,train_loss:0.051803939044475555,train_acc:0.9858630895614624\n",
      "step:1017,train_loss:0.06192094832658768,train_acc:0.9799107313156128\n",
      "step:1018,train_loss:0.06909140944480896,train_acc:0.976190447807312\n",
      "step:1019,train_loss:0.0690525621175766,train_acc:0.976934552192688\n",
      "step:1020,train_loss:0.07215119898319244,train_acc:0.9754464030265808\n",
      "step:1021,train_loss:0.08128101378679276,train_acc:0.9732142686843872\n",
      "step:1022,train_loss:0.06996656954288483,train_acc:0.9776785969734192\n",
      "step:1023,train_loss:0.049147650599479675,train_acc:0.9851190447807312\n",
      "step:1024,train_loss:0.06329439580440521,train_acc:0.984375\n",
      "step:1025,train_loss:0.05738938972353935,train_acc:0.9851190447807312\n",
      "step:1026,train_loss:0.06129619479179382,train_acc:0.9791666865348816\n",
      "step:1027,train_loss:0.06004079803824425,train_acc:0.984375\n",
      "step:1028,train_loss:0.05886445194482803,train_acc:0.9828869104385376\n",
      "step:1029,train_loss:0.06835640966892242,train_acc:0.972470223903656\n",
      "step:1030,train_loss:0.06090683117508888,train_acc:0.9828869104385376\n",
      "step:1031,train_loss:0.07656289637088776,train_acc:0.972470223903656\n",
      "step:1032,train_loss:0.06856952607631683,train_acc:0.9747023582458496\n",
      "step:1033,train_loss:0.0620981864631176,train_acc:0.9813988208770752\n",
      "step:1034,train_loss:0.058669544756412506,train_acc:0.9821428656578064\n",
      "step:1035,train_loss:0.057899363338947296,train_acc:0.9836309552192688\n",
      "step:1036,train_loss:0.06899159401655197,train_acc:0.9821428656578064\n",
      "step:1037,train_loss:0.06479782611131668,train_acc:0.9821428656578064\n",
      "step:1038,train_loss:0.05459695681929588,train_acc:0.9828869104385376\n",
      "step:1039,train_loss:0.04826844483613968,train_acc:0.9873511791229248\n",
      "step:1040,train_loss:0.05801356956362724,train_acc:0.9799107313156128\n",
      "step:1041,train_loss:0.07802236080169678,train_acc:0.9702380895614624\n",
      "step:1042,train_loss:0.046492379158735275,train_acc:0.988095223903656\n",
      "step:1043,train_loss:0.054705459624528885,train_acc:0.9851190447807312\n",
      "step:1044,train_loss:0.04926394298672676,train_acc:0.988095223903656\n",
      "step:1045,train_loss:0.0479385107755661,train_acc:0.9888392686843872\n",
      "step:1046,train_loss:0.05485350638628006,train_acc:0.9851190447807312\n",
      "step:1047,train_loss:0.05785859376192093,train_acc:0.9866071343421936\n",
      "step:1048,train_loss:0.061191171407699585,train_acc:0.9828869104385376\n",
      "step:1049,train_loss:0.055184461176395416,train_acc:0.9866071343421936\n",
      "step:1050,train_loss:0.0741940587759018,train_acc:0.9776785969734192\n",
      "val_acc:0.9923115173975626\n",
      "step:1051,train_loss:0.05328304320573807,train_acc:0.9858630895614624\n",
      "step:1052,train_loss:0.05736667662858963,train_acc:0.988095223903656\n",
      "step:1053,train_loss:0.050247449427843094,train_acc:0.9851190447807312\n",
      "step:1054,train_loss:0.048232339322566986,train_acc:0.9866071343421936\n",
      "step:1055,train_loss:0.056649621576070786,train_acc:0.9813988208770752\n",
      "step:1056,train_loss:0.047984253615140915,train_acc:0.9873511791229248\n",
      "step:1057,train_loss:0.0440019853413105,train_acc:0.9910714030265808\n",
      "step:1058,train_loss:0.07383932173252106,train_acc:0.972470223903656\n",
      "step:1059,train_loss:0.06312252581119537,train_acc:0.980654776096344\n",
      "step:1060,train_loss:0.06038514897227287,train_acc:0.9828869104385376\n",
      "step:1061,train_loss:0.06843683868646622,train_acc:0.9739583134651184\n",
      "step:1062,train_loss:0.061734143644571304,train_acc:0.9828869104385376\n",
      "step:1063,train_loss:0.04912323132157326,train_acc:0.988095223903656\n",
      "step:1064,train_loss:0.06456442922353745,train_acc:0.9791666865348816\n",
      "step:1065,train_loss:0.07140751928091049,train_acc:0.972470223903656\n",
      "step:1066,train_loss:0.07560957968235016,train_acc:0.9732142686843872\n",
      "step:1067,train_loss:0.05511980876326561,train_acc:0.9836309552192688\n",
      "step:1068,train_loss:0.034401003271341324,train_acc:0.9933035969734192\n",
      "step:1069,train_loss:0.03631118685007095,train_acc:0.9933035969734192\n",
      "step:1070,train_loss:0.04644983634352684,train_acc:0.9888392686843872\n",
      "step:1071,train_loss:0.06410133838653564,train_acc:0.976190447807312\n",
      "step:1072,train_loss:0.05365205928683281,train_acc:0.9873511791229248\n",
      "step:1073,train_loss:0.04900926724076271,train_acc:0.9873511791229248\n",
      "step:1074,train_loss:0.03799717500805855,train_acc:0.9933035969734192\n",
      "step:1075,train_loss:0.04866306483745575,train_acc:0.9873511791229248\n",
      "step:1076,train_loss:0.05354272574186325,train_acc:0.984375\n",
      "step:1077,train_loss:0.05564521998167038,train_acc:0.9836309552192688\n",
      "step:1078,train_loss:0.04696773365139961,train_acc:0.9851190447807312\n",
      "step:1079,train_loss:0.05671010538935661,train_acc:0.9813988208770752\n",
      "step:1080,train_loss:0.0652296170592308,train_acc:0.9784226417541504\n",
      "step:1081,train_loss:0.05641184002161026,train_acc:0.9813988208770752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1082,train_loss:0.04342745617032051,train_acc:0.9903273582458496\n",
      "step:1083,train_loss:0.03931839391589165,train_acc:0.991815447807312\n",
      "step:1084,train_loss:0.04949335753917694,train_acc:0.9858630895614624\n",
      "step:1085,train_loss:0.047349922358989716,train_acc:0.9873511791229248\n",
      "step:1086,train_loss:0.07248806953430176,train_acc:0.9754464030265808\n",
      "step:1087,train_loss:0.040484413504600525,train_acc:0.9910714030265808\n",
      "step:1088,train_loss:0.058938246220350266,train_acc:0.9851190447807312\n",
      "step:1089,train_loss:0.04603002592921257,train_acc:0.988095223903656\n",
      "step:1090,train_loss:0.048420656472444534,train_acc:0.9910714030265808\n",
      "step:1091,train_loss:0.056869085878133774,train_acc:0.9828869104385376\n",
      "step:1092,train_loss:0.040724460035562515,train_acc:0.991815447807312\n",
      "step:1093,train_loss:0.04263424873352051,train_acc:0.991815447807312\n",
      "step:1094,train_loss:0.06022197753190994,train_acc:0.9784226417541504\n",
      "step:1095,train_loss:0.051335517317056656,train_acc:0.9851190447807312\n",
      "step:1096,train_loss:0.058221928775310516,train_acc:0.9836309552192688\n",
      "step:1097,train_loss:0.046999767422676086,train_acc:0.9903273582458496\n",
      "step:1098,train_loss:0.05222150310873985,train_acc:0.9851190447807312\n",
      "step:1099,train_loss:0.05918971821665764,train_acc:0.9813988208770752\n",
      "step:1100,train_loss:0.06143151968717575,train_acc:0.9784226417541504\n",
      "val_acc:0.9957837462425232\n",
      "step:1101,train_loss:0.051857709884643555,train_acc:0.9873511791229248\n",
      "step:1102,train_loss:0.04791409522294998,train_acc:0.9866071343421936\n",
      "step:1103,train_loss:0.03858058899641037,train_acc:0.9947916865348816\n",
      "step:1104,train_loss:0.03698879852890968,train_acc:0.9940476417541504\n",
      "step:1105,train_loss:0.04892361909151077,train_acc:0.9873511791229248\n",
      "step:1106,train_loss:0.04976687952876091,train_acc:0.9858630895614624\n",
      "step:1107,train_loss:0.0473722368478775,train_acc:0.988095223903656\n",
      "step:1108,train_loss:0.04646192118525505,train_acc:0.9895833134651184\n",
      "step:1109,train_loss:0.04383758828043938,train_acc:0.9888392686843872\n",
      "step:1110,train_loss:0.042679231613874435,train_acc:0.9888392686843872\n",
      "step:1111,train_loss:0.039134472608566284,train_acc:0.992559552192688\n",
      "step:1112,train_loss:0.04838967323303223,train_acc:0.9873511791229248\n",
      "step:1113,train_loss:0.04368337616324425,train_acc:0.9888392686843872\n",
      "step:1114,train_loss:0.055741697549819946,train_acc:0.9813988208770752\n",
      "step:1115,train_loss:0.04360030218958855,train_acc:0.9866071343421936\n",
      "step:1116,train_loss:0.04868640378117561,train_acc:0.9858630895614624\n",
      "step:1117,train_loss:0.07165905088186264,train_acc:0.9739583134651184\n",
      "step:1118,train_loss:0.04202273488044739,train_acc:0.9910714030265808\n",
      "step:1119,train_loss:0.039259620010852814,train_acc:0.9903273582458496\n",
      "step:1120,train_loss:0.061529286205768585,train_acc:0.980654776096344\n",
      "step:1121,train_loss:0.03925927355885506,train_acc:0.996279776096344\n",
      "step:1122,train_loss:0.0503813810646534,train_acc:0.988095223903656\n",
      "step:1123,train_loss:0.03614729270339012,train_acc:0.996279776096344\n",
      "step:1124,train_loss:0.04454365372657776,train_acc:0.9895833134651184\n",
      "step:1125,train_loss:0.048051681369543076,train_acc:0.984375\n",
      "step:1126,train_loss:0.0476251095533371,train_acc:0.988095223903656\n",
      "step:1127,train_loss:0.052054762840270996,train_acc:0.9866071343421936\n",
      "step:1128,train_loss:0.03916657716035843,train_acc:0.991815447807312\n",
      "step:1129,train_loss:0.03830762580037117,train_acc:0.9903273582458496\n",
      "step:1130,train_loss:0.046069853007793427,train_acc:0.9866071343421936\n",
      "step:1131,train_loss:0.05048960819840431,train_acc:0.9851190447807312\n",
      "step:1132,train_loss:0.03872785344719887,train_acc:0.9910714030265808\n",
      "step:1133,train_loss:0.05469295382499695,train_acc:0.9784226417541504\n",
      "step:1134,train_loss:0.05908733233809471,train_acc:0.980654776096344\n",
      "step:1135,train_loss:0.03934917971491814,train_acc:0.9933035969734192\n",
      "step:1136,train_loss:0.03020665980875492,train_acc:0.992559552192688\n",
      "step:1137,train_loss:0.0436403863132,train_acc:0.988095223903656\n",
      "step:1138,train_loss:0.05199248343706131,train_acc:0.9851190447807312\n",
      "step:1139,train_loss:0.040658675134181976,train_acc:0.9910714030265808\n",
      "step:1140,train_loss:0.0390559621155262,train_acc:0.9903273582458496\n",
      "step:1141,train_loss:0.04612857848405838,train_acc:0.9873511791229248\n",
      "step:1142,train_loss:0.043023332953453064,train_acc:0.9866071343421936\n",
      "step:1143,train_loss:0.041067760437726974,train_acc:0.988095223903656\n",
      "step:1144,train_loss:0.04864655062556267,train_acc:0.9858630895614624\n",
      "step:1145,train_loss:0.042743247002363205,train_acc:0.9888392686843872\n",
      "step:1146,train_loss:0.053521256893873215,train_acc:0.9851190447807312\n",
      "step:1147,train_loss:0.03822632133960724,train_acc:0.9933035969734192\n",
      "step:1148,train_loss:0.04092152789235115,train_acc:0.9910714030265808\n",
      "step:1149,train_loss:0.055068060755729675,train_acc:0.9813988208770752\n",
      "step:1150,train_loss:0.052774958312511444,train_acc:0.984375\n",
      "val_acc:0.9947916865348816\n",
      "step:1151,train_loss:0.04087193310260773,train_acc:0.9895833134651184\n",
      "step:1152,train_loss:0.04363387078046799,train_acc:0.9858630895614624\n",
      "step:1153,train_loss:0.03758378326892853,train_acc:0.992559552192688\n",
      "step:1154,train_loss:0.035260025411844254,train_acc:0.9933035969734192\n",
      "step:1155,train_loss:0.06200193241238594,train_acc:0.980654776096344\n",
      "step:1156,train_loss:0.040719397366046906,train_acc:0.9910714030265808\n",
      "step:1157,train_loss:0.04862495884299278,train_acc:0.9866071343421936\n",
      "step:1158,train_loss:0.0551937073469162,train_acc:0.9799107313156128\n",
      "step:1159,train_loss:0.044530801475048065,train_acc:0.9858630895614624\n",
      "step:1160,train_loss:0.04831387475132942,train_acc:0.9888392686843872\n",
      "step:1161,train_loss:0.04008498787879944,train_acc:0.991815447807312\n",
      "step:1162,train_loss:0.046777430921792984,train_acc:0.9873511791229248\n",
      "step:1163,train_loss:0.04242716357111931,train_acc:0.9858630895614624\n",
      "step:1164,train_loss:0.040781207382678986,train_acc:0.992559552192688\n",
      "step:1165,train_loss:0.04973217472434044,train_acc:0.9851190447807312\n",
      "step:1166,train_loss:0.042385030537843704,train_acc:0.988095223903656\n",
      "step:1167,train_loss:0.04885436221957207,train_acc:0.9836309552192688\n",
      "step:1168,train_loss:0.04486319422721863,train_acc:0.9903273582458496\n",
      "step:1169,train_loss:0.048972055315971375,train_acc:0.984375\n",
      "step:1170,train_loss:0.03736964613199234,train_acc:0.9895833134651184\n",
      "step:1171,train_loss:0.04449211806058884,train_acc:0.988095223903656\n",
      "step:1172,train_loss:0.05698386952280998,train_acc:0.984375\n",
      "step:1173,train_loss:0.043108440935611725,train_acc:0.988095223903656\n",
      "step:1174,train_loss:0.04670117422938347,train_acc:0.9888392686843872\n",
      "step:1175,train_loss:0.03605644032359123,train_acc:0.9933035969734192\n",
      "step:1176,train_loss:0.029904689639806747,train_acc:0.9955357313156128\n",
      "step:1177,train_loss:0.039742305874824524,train_acc:0.9895833134651184\n",
      "step:1178,train_loss:0.03381049633026123,train_acc:0.992559552192688\n",
      "step:1179,train_loss:0.047627776861190796,train_acc:0.9851190447807312\n",
      "step:1180,train_loss:0.04135198891162872,train_acc:0.9888392686843872\n",
      "step:1181,train_loss:0.04235800728201866,train_acc:0.9873511791229248\n",
      "step:1182,train_loss:0.06115492060780525,train_acc:0.9791666865348816\n",
      "step:1183,train_loss:0.0412859283387661,train_acc:0.9910714030265808\n",
      "step:1184,train_loss:0.03406083211302757,train_acc:0.9895833134651184\n",
      "step:1185,train_loss:0.038901470601558685,train_acc:0.9910714030265808\n",
      "step:1186,train_loss:0.04191736504435539,train_acc:0.9895833134651184\n",
      "step:1187,train_loss:0.06070273369550705,train_acc:0.9791666865348816\n",
      "step:1188,train_loss:0.03925611823797226,train_acc:0.988095223903656\n",
      "step:1189,train_loss:0.03947629779577255,train_acc:0.9933035969734192\n",
      "step:1190,train_loss:0.028640015050768852,train_acc:0.9933035969734192\n",
      "step:1191,train_loss:0.034598905593156815,train_acc:0.9933035969734192\n",
      "step:1192,train_loss:0.030682552605867386,train_acc:0.9933035969734192\n",
      "step:1193,train_loss:0.036660853773355484,train_acc:0.992559552192688\n",
      "step:1194,train_loss:0.03701082989573479,train_acc:0.991815447807312\n",
      "step:1195,train_loss:0.0600326843559742,train_acc:0.9784226417541504\n",
      "step:1196,train_loss:0.04230042174458504,train_acc:0.9903273582458496\n",
      "step:1197,train_loss:0.04717234522104263,train_acc:0.984375\n",
      "step:1198,train_loss:0.05419382452964783,train_acc:0.9813988208770752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1199,train_loss:0.048234183341264725,train_acc:0.9858630895614624\n",
      "step:1200,train_loss:0.030245451256632805,train_acc:0.9940476417541504\n",
      "val_acc:0.9940476218859354\n",
      "step:1201,train_loss:0.05271107703447342,train_acc:0.984375\n",
      "step:1202,train_loss:0.0465945303440094,train_acc:0.9851190447807312\n",
      "step:1203,train_loss:0.03965500369668007,train_acc:0.9903273582458496\n",
      "step:1204,train_loss:0.038912706077098846,train_acc:0.991815447807312\n",
      "step:1205,train_loss:0.06188703328371048,train_acc:0.9784226417541504\n",
      "step:1206,train_loss:0.05941386520862579,train_acc:0.9776785969734192\n",
      "step:1207,train_loss:0.03766004741191864,train_acc:0.988095223903656\n",
      "step:1208,train_loss:0.037913862615823746,train_acc:0.9910714030265808\n",
      "step:1209,train_loss:0.03790724277496338,train_acc:0.9895833134651184\n",
      "step:1210,train_loss:0.03154882788658142,train_acc:0.9955357313156128\n",
      "step:1211,train_loss:0.035044483840465546,train_acc:0.9903273582458496\n",
      "step:1212,train_loss:0.03974161669611931,train_acc:0.988095223903656\n",
      "step:1213,train_loss:0.04607384279370308,train_acc:0.9873511791229248\n",
      "step:1214,train_loss:0.05610425025224686,train_acc:0.9828869104385376\n",
      "step:1215,train_loss:0.03992198780179024,train_acc:0.9888392686843872\n",
      "step:1216,train_loss:0.03135580196976662,train_acc:0.996279776096344\n",
      "step:1217,train_loss:0.03282986581325531,train_acc:0.992559552192688\n",
      "step:1218,train_loss:0.04264068230986595,train_acc:0.988095223903656\n",
      "step:1219,train_loss:0.03204439952969551,train_acc:0.991815447807312\n",
      "step:1220,train_loss:0.04714629426598549,train_acc:0.9858630895614624\n",
      "step:1221,train_loss:0.041302554309368134,train_acc:0.9866071343421936\n",
      "step:1222,train_loss:0.0464622788131237,train_acc:0.984375\n",
      "step:1223,train_loss:0.032969240099191666,train_acc:0.992559552192688\n",
      "step:1224,train_loss:0.03251015394926071,train_acc:0.9895833134651184\n",
      "step:1225,train_loss:0.03258206695318222,train_acc:0.9955357313156128\n",
      "step:1226,train_loss:0.04296867921948433,train_acc:0.9895833134651184\n",
      "step:1227,train_loss:0.04219333454966545,train_acc:0.9866071343421936\n",
      "step:1228,train_loss:0.0364733524620533,train_acc:0.9933035969734192\n",
      "step:1229,train_loss:0.03106085956096649,train_acc:0.996279776096344\n",
      "step:1230,train_loss:0.043258264660835266,train_acc:0.9873511791229248\n",
      "step:1231,train_loss:0.03633221611380577,train_acc:0.9903273582458496\n",
      "step:1232,train_loss:0.050758667290210724,train_acc:0.9836309552192688\n",
      "step:1233,train_loss:0.03584248945116997,train_acc:0.991815447807312\n",
      "step:1234,train_loss:0.04375867173075676,train_acc:0.9873511791229248\n",
      "step:1235,train_loss:0.03404173627495766,train_acc:0.9903273582458496\n",
      "step:1236,train_loss:0.034519098699092865,train_acc:0.9947916865348816\n",
      "step:1237,train_loss:0.0609760582447052,train_acc:0.976934552192688\n",
      "step:1238,train_loss:0.0383581817150116,train_acc:0.9903273582458496\n",
      "step:1239,train_loss:0.03687969967722893,train_acc:0.992559552192688\n",
      "step:1240,train_loss:0.04128635674715042,train_acc:0.988095223903656\n",
      "step:1241,train_loss:0.034160155802965164,train_acc:0.991815447807312\n",
      "step:1242,train_loss:0.04743807762861252,train_acc:0.9851190447807312\n",
      "step:1243,train_loss:0.03307652845978737,train_acc:0.9910714030265808\n",
      "step:1244,train_loss:0.02792457491159439,train_acc:0.9970238208770752\n",
      "step:1245,train_loss:0.02791263908147812,train_acc:0.9933035969734192\n",
      "step:1246,train_loss:0.03567536175251007,train_acc:0.988095223903656\n",
      "step:1247,train_loss:0.028401222079992294,train_acc:0.9970238208770752\n",
      "step:1248,train_loss:0.03143753856420517,train_acc:0.9940476417541504\n",
      "step:1249,train_loss:0.0377223826944828,train_acc:0.991815447807312\n",
      "step:1250,train_loss:0.03553460165858269,train_acc:0.991815447807312\n",
      "val_acc:0.9952877163887024\n",
      "step:1251,train_loss:0.038463737815618515,train_acc:0.9903273582458496\n",
      "step:1252,train_loss:0.03139246255159378,train_acc:0.992559552192688\n",
      "step:1253,train_loss:0.03785392642021179,train_acc:0.9895833134651184\n",
      "step:1254,train_loss:0.04587030038237572,train_acc:0.9858630895614624\n",
      "step:1255,train_loss:0.035464197397232056,train_acc:0.992559552192688\n",
      "step:1256,train_loss:0.057828277349472046,train_acc:0.9799107313156128\n",
      "step:1257,train_loss:0.029983656480908394,train_acc:0.9933035969734192\n",
      "step:1258,train_loss:0.044673409312963486,train_acc:0.9873511791229248\n",
      "step:1259,train_loss:0.02366858534514904,train_acc:0.9947916865348816\n",
      "step:1260,train_loss:0.04831961169838905,train_acc:0.9813988208770752\n",
      "step:1261,train_loss:0.036578599363565445,train_acc:0.9940476417541504\n",
      "step:1262,train_loss:0.043155789375305176,train_acc:0.9888392686843872\n",
      "step:1263,train_loss:0.028432460501790047,train_acc:0.996279776096344\n",
      "step:1264,train_loss:0.033687740564346313,train_acc:0.991815447807312\n",
      "step:1265,train_loss:0.03306050971150398,train_acc:0.991815447807312\n",
      "step:1266,train_loss:0.029464880004525185,train_acc:0.9947916865348816\n",
      "step:1267,train_loss:0.03427687659859657,train_acc:0.9955357313156128\n",
      "step:1268,train_loss:0.029225261881947517,train_acc:0.9940476417541504\n",
      "step:1269,train_loss:0.029012029990553856,train_acc:0.9970238208770752\n",
      "step:1270,train_loss:0.03796974942088127,train_acc:0.9873511791229248\n",
      "step:1271,train_loss:0.02367408759891987,train_acc:0.9977678656578064\n",
      "step:1272,train_loss:0.030348708853125572,train_acc:0.9933035969734192\n",
      "step:1273,train_loss:0.04143251106142998,train_acc:0.9888392686843872\n",
      "step:1274,train_loss:0.03708527609705925,train_acc:0.9933035969734192\n",
      "step:1275,train_loss:0.03237445652484894,train_acc:0.992559552192688\n",
      "step:1276,train_loss:0.03262019157409668,train_acc:0.9910714030265808\n",
      "step:1277,train_loss:0.03653790429234505,train_acc:0.9895833134651184\n",
      "step:1278,train_loss:0.03200661018490791,train_acc:0.9933035969734192\n",
      "step:1279,train_loss:0.040688175708055496,train_acc:0.9851190447807312\n",
      "step:1280,train_loss:0.0300104022026062,train_acc:0.9933035969734192\n",
      "step:1281,train_loss:0.054427046328783035,train_acc:0.9799107313156128\n",
      "step:1282,train_loss:0.0324629470705986,train_acc:0.992559552192688\n",
      "step:1283,train_loss:0.03006480634212494,train_acc:0.9940476417541504\n",
      "step:1284,train_loss:0.0360296294093132,train_acc:0.9903273582458496\n",
      "step:1285,train_loss:0.030188854783773422,train_acc:0.9940476417541504\n",
      "step:1286,train_loss:0.034502800554037094,train_acc:0.9910714030265808\n",
      "step:1287,train_loss:0.03185185045003891,train_acc:0.9940476417541504\n",
      "step:1288,train_loss:0.034791845828294754,train_acc:0.992559552192688\n",
      "step:1289,train_loss:0.02653830125927925,train_acc:0.9977678656578064\n",
      "step:1290,train_loss:0.028261909261345863,train_acc:0.9940476417541504\n",
      "step:1291,train_loss:0.02945506013929844,train_acc:0.9955357313156128\n",
      "step:1292,train_loss:0.037140268832445145,train_acc:0.9903273582458496\n",
      "step:1293,train_loss:0.033675190061330795,train_acc:0.991815447807312\n",
      "step:1294,train_loss:0.03336728736758232,train_acc:0.992559552192688\n",
      "step:1295,train_loss:0.03792863339185715,train_acc:0.9910714030265808\n",
      "step:1296,train_loss:0.029298463836312294,train_acc:0.9933035969734192\n",
      "step:1297,train_loss:0.04332919791340828,train_acc:0.9873511791229248\n",
      "step:1298,train_loss:0.032590221613645554,train_acc:0.9933035969734192\n",
      "step:1299,train_loss:0.030467890202999115,train_acc:0.9940476417541504\n",
      "step:1300,train_loss:0.03635876998305321,train_acc:0.988095223903656\n",
      "val_acc:0.997519850730896\n",
      "step:1301,train_loss:0.028803518041968346,train_acc:0.9940476417541504\n",
      "step:1302,train_loss:0.030447840690612793,train_acc:0.992559552192688\n",
      "step:1303,train_loss:0.027370963245630264,train_acc:0.9933035969734192\n",
      "step:1304,train_loss:0.03148026019334793,train_acc:0.9940476417541504\n",
      "step:1305,train_loss:0.03751120716333389,train_acc:0.9888392686843872\n",
      "step:1306,train_loss:0.024427073076367378,train_acc:0.996279776096344\n",
      "step:1307,train_loss:0.029592463746666908,train_acc:0.9955357313156128\n",
      "step:1308,train_loss:0.021688755601644516,train_acc:0.9985119104385376\n",
      "step:1309,train_loss:0.027395877987146378,train_acc:0.9933035969734192\n",
      "step:1310,train_loss:0.0276420209556818,train_acc:0.9940476417541504\n",
      "step:1311,train_loss:0.028304006904363632,train_acc:0.9947916865348816\n",
      "step:1312,train_loss:0.025065740570425987,train_acc:0.9955357313156128\n",
      "step:1313,train_loss:0.05713978782296181,train_acc:0.9799107313156128\n",
      "step:1314,train_loss:0.027720525860786438,train_acc:0.9955357313156128\n",
      "step:1315,train_loss:0.031790539622306824,train_acc:0.992559552192688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1316,train_loss:0.02412986382842064,train_acc:0.9955357313156128\n",
      "step:1317,train_loss:0.0334741547703743,train_acc:0.992559552192688\n",
      "step:1318,train_loss:0.03514297679066658,train_acc:0.9895833134651184\n",
      "step:1319,train_loss:0.04478837922215462,train_acc:0.9866071343421936\n",
      "step:1320,train_loss:0.03141095116734505,train_acc:0.9933035969734192\n",
      "step:1321,train_loss:0.032229140400886536,train_acc:0.9910714030265808\n",
      "step:1322,train_loss:0.023764299228787422,train_acc:0.9970238208770752\n",
      "step:1323,train_loss:0.025430889800190926,train_acc:0.9940476417541504\n",
      "step:1324,train_loss:0.025643240660429,train_acc:0.9933035969734192\n",
      "step:1325,train_loss:0.029495732858777046,train_acc:0.9947916865348816\n",
      "step:1326,train_loss:0.02632150985300541,train_acc:0.9947916865348816\n",
      "step:1327,train_loss:0.02183091640472412,train_acc:0.9977678656578064\n",
      "step:1328,train_loss:0.027809759601950645,train_acc:0.9955357313156128\n",
      "step:1329,train_loss:0.030392510816454887,train_acc:0.9940476417541504\n",
      "step:1330,train_loss:0.025190381333231926,train_acc:0.9955357313156128\n",
      "step:1331,train_loss:0.020343396812677383,train_acc:0.9992559552192688\n",
      "step:1332,train_loss:0.033300239592790604,train_acc:0.991815447807312\n",
      "step:1333,train_loss:0.041249148547649384,train_acc:0.9888392686843872\n",
      "step:1334,train_loss:0.0307514276355505,train_acc:0.9910714030265808\n",
      "step:1335,train_loss:0.024509157985448837,train_acc:0.9970238208770752\n",
      "step:1336,train_loss:0.025757692754268646,train_acc:0.9933035969734192\n",
      "step:1337,train_loss:0.024022260680794716,train_acc:0.9955357313156128\n",
      "step:1338,train_loss:0.020818743854761124,train_acc:0.9985119104385376\n",
      "step:1339,train_loss:0.029216274619102478,train_acc:0.9947916865348816\n",
      "step:1340,train_loss:0.028924178332090378,train_acc:0.992559552192688\n",
      "step:1341,train_loss:0.02353690192103386,train_acc:0.9940476417541504\n",
      "step:1342,train_loss:0.022516917437314987,train_acc:0.9955357313156128\n",
      "step:1343,train_loss:0.03510288521647453,train_acc:0.9895833134651184\n",
      "step:1344,train_loss:0.041243039071559906,train_acc:0.9895833134651184\n",
      "step:1345,train_loss:0.03245032951235771,train_acc:0.9940476417541504\n",
      "step:1346,train_loss:0.032434456050395966,train_acc:0.991815447807312\n",
      "step:1347,train_loss:0.029616810381412506,train_acc:0.9940476417541504\n",
      "step:1348,train_loss:0.02684558555483818,train_acc:0.9947916865348816\n",
      "step:1349,train_loss:0.025909515097737312,train_acc:0.9947916865348816\n",
      "step:1350,train_loss:0.019718632102012634,train_acc:0.9985119104385376\n",
      "val_acc:0.9982638955116272\n",
      "step:1351,train_loss:0.035215817391872406,train_acc:0.991815447807312\n",
      "step:1352,train_loss:0.02432527393102646,train_acc:0.996279776096344\n",
      "step:1353,train_loss:0.030119072645902634,train_acc:0.992559552192688\n",
      "step:1354,train_loss:0.02094275876879692,train_acc:0.9955357313156128\n",
      "step:1355,train_loss:0.02638762816786766,train_acc:0.9947916865348816\n",
      "step:1356,train_loss:0.030156388878822327,train_acc:0.9910714030265808\n",
      "step:1357,train_loss:0.04309888929128647,train_acc:0.9895833134651184\n",
      "step:1358,train_loss:0.020352359861135483,train_acc:1.0\n",
      "step:1359,train_loss:0.030179370194673538,train_acc:0.9933035969734192\n",
      "step:1360,train_loss:0.02420000173151493,train_acc:0.9947916865348816\n",
      "step:1361,train_loss:0.03448900580406189,train_acc:0.991815447807312\n",
      "step:1362,train_loss:0.03566258028149605,train_acc:0.9888392686843872\n",
      "step:1363,train_loss:0.024934865534305573,train_acc:0.9940476417541504\n",
      "step:1364,train_loss:0.01829000934958458,train_acc:0.996279776096344\n",
      "step:1365,train_loss:0.025448963046073914,train_acc:0.9947916865348816\n",
      "step:1366,train_loss:0.04264670982956886,train_acc:0.9828869104385376\n",
      "step:1367,train_loss:0.025362519547343254,train_acc:0.9940476417541504\n",
      "step:1368,train_loss:0.03244154900312424,train_acc:0.9910714030265808\n",
      "step:1369,train_loss:0.022802386432886124,train_acc:0.9977678656578064\n",
      "step:1370,train_loss:0.036792464554309845,train_acc:0.9933035969734192\n",
      "step:1371,train_loss:0.02948751114308834,train_acc:0.992559552192688\n",
      "step:1372,train_loss:0.031627316027879715,train_acc:0.9947916865348816\n",
      "step:1373,train_loss:0.027498528361320496,train_acc:0.991815447807312\n",
      "step:1374,train_loss:0.02950325421988964,train_acc:0.992559552192688\n",
      "step:1375,train_loss:0.024438222870230675,train_acc:0.9977678656578064\n",
      "step:1376,train_loss:0.02122313156723976,train_acc:0.9977678656578064\n",
      "step:1377,train_loss:0.029125088825821877,train_acc:0.9947916865348816\n",
      "step:1378,train_loss:0.04213213548064232,train_acc:0.9873511791229248\n",
      "step:1379,train_loss:0.021605106070637703,train_acc:0.9970238208770752\n",
      "step:1380,train_loss:0.019159844145178795,train_acc:0.9970238208770752\n",
      "step:1381,train_loss:0.02028651535511017,train_acc:0.9977678656578064\n",
      "step:1382,train_loss:0.028728093951940536,train_acc:0.9940476417541504\n",
      "step:1383,train_loss:0.022473638877272606,train_acc:0.9985119104385376\n",
      "step:1384,train_loss:0.04149620980024338,train_acc:0.9851190447807312\n",
      "step:1385,train_loss:0.024560028687119484,train_acc:0.9947916865348816\n",
      "step:1386,train_loss:0.020726822316646576,train_acc:0.9970238208770752\n",
      "step:1387,train_loss:0.033905159682035446,train_acc:0.991815447807312\n",
      "step:1388,train_loss:0.02224539965391159,train_acc:0.9985119104385376\n",
      "step:1389,train_loss:0.026562413200736046,train_acc:0.9940476417541504\n",
      "step:1390,train_loss:0.021937556564807892,train_acc:0.996279776096344\n",
      "step:1391,train_loss:0.025941768661141396,train_acc:0.992559552192688\n",
      "step:1392,train_loss:0.030074957758188248,train_acc:0.991815447807312\n",
      "step:1393,train_loss:0.029081109911203384,train_acc:0.9903273582458496\n",
      "step:1394,train_loss:0.017580954357981682,train_acc:0.9977678656578064\n",
      "step:1395,train_loss:0.03430720046162605,train_acc:0.9895833134651184\n",
      "step:1396,train_loss:0.026772992685437202,train_acc:0.9955357313156128\n",
      "step:1397,train_loss:0.024142108857631683,train_acc:0.996279776096344\n",
      "step:1398,train_loss:0.023061731830239296,train_acc:0.9955357313156128\n",
      "step:1399,train_loss:0.025303147733211517,train_acc:0.996279776096344\n",
      "step:1400,train_loss:0.02375015988945961,train_acc:0.9970238208770752\n",
      "val_acc:0.9967758059501648\n",
      "step:1401,train_loss:0.02409273386001587,train_acc:0.9947916865348816\n",
      "step:1402,train_loss:0.024256331846117973,train_acc:0.9955357313156128\n",
      "step:1403,train_loss:0.02652527578175068,train_acc:0.996279776096344\n",
      "step:1404,train_loss:0.020399918779730797,train_acc:0.9977678656578064\n",
      "step:1405,train_loss:0.02083933912217617,train_acc:0.9970238208770752\n",
      "step:1406,train_loss:0.019183488562703133,train_acc:0.9977678656578064\n",
      "step:1407,train_loss:0.025290921330451965,train_acc:0.9955357313156128\n",
      "step:1408,train_loss:0.021956829354166985,train_acc:0.996279776096344\n",
      "step:1409,train_loss:0.021058131009340286,train_acc:0.9977678656578064\n",
      "step:1410,train_loss:0.018189989030361176,train_acc:0.9985119104385376\n",
      "step:1411,train_loss:0.018381377682089806,train_acc:0.9970238208770752\n",
      "step:1412,train_loss:0.02597280964255333,train_acc:0.9910714030265808\n",
      "step:1413,train_loss:0.02066844329237938,train_acc:0.9977678656578064\n",
      "step:1414,train_loss:0.02299005724489689,train_acc:0.9955357313156128\n",
      "step:1415,train_loss:0.02960321493446827,train_acc:0.992559552192688\n",
      "step:1416,train_loss:0.022450977936387062,train_acc:0.9955357313156128\n",
      "step:1417,train_loss:0.02673109993338585,train_acc:0.996279776096344\n",
      "step:1418,train_loss:0.023657122626900673,train_acc:0.9940476417541504\n",
      "step:1419,train_loss:0.0177126694470644,train_acc:0.9985119104385376\n",
      "step:1420,train_loss:0.020780732855200768,train_acc:0.9970238208770752\n",
      "step:1421,train_loss:0.042828917503356934,train_acc:0.9836309552192688\n",
      "step:1422,train_loss:0.02854692004621029,train_acc:0.9933035969734192\n",
      "step:1423,train_loss:0.029221512377262115,train_acc:0.991815447807312\n",
      "step:1424,train_loss:0.026700394228100777,train_acc:0.9955357313156128\n",
      "step:1425,train_loss:0.022127147763967514,train_acc:0.9970238208770752\n",
      "step:1426,train_loss:0.017436081543564796,train_acc:0.9985119104385376\n",
      "step:1427,train_loss:0.024447014555335045,train_acc:0.991815447807312\n",
      "step:1428,train_loss:0.02531450055539608,train_acc:0.9933035969734192\n",
      "step:1429,train_loss:0.01689903438091278,train_acc:0.9970238208770752\n",
      "step:1430,train_loss:0.020145751535892487,train_acc:0.9977678656578064\n",
      "step:1431,train_loss:0.015943225473165512,train_acc:0.9992559552192688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1432,train_loss:0.02306828647851944,train_acc:0.9970238208770752\n",
      "step:1433,train_loss:0.01388230174779892,train_acc:0.9992559552192688\n",
      "step:1434,train_loss:0.029169581830501556,train_acc:0.992559552192688\n",
      "step:1435,train_loss:0.03366515040397644,train_acc:0.991815447807312\n",
      "step:1436,train_loss:0.020151546224951744,train_acc:0.996279776096344\n",
      "step:1437,train_loss:0.019535623490810394,train_acc:0.9985119104385376\n",
      "step:1438,train_loss:0.025145672261714935,train_acc:0.9940476417541504\n",
      "step:1439,train_loss:0.026058098301291466,train_acc:0.9947916865348816\n",
      "step:1440,train_loss:0.021057628095149994,train_acc:0.9977678656578064\n",
      "step:1441,train_loss:0.021664246916770935,train_acc:0.9970238208770752\n",
      "step:1442,train_loss:0.017614472657442093,train_acc:0.9985119104385376\n",
      "step:1443,train_loss:0.023425955325365067,train_acc:0.9955357313156128\n",
      "step:1444,train_loss:0.016233021393418312,train_acc:0.9985119104385376\n",
      "step:1445,train_loss:0.02874247170984745,train_acc:0.991815447807312\n",
      "step:1446,train_loss:0.018718406558036804,train_acc:0.9992559552192688\n",
      "step:1447,train_loss:0.025692814961075783,train_acc:0.9940476417541504\n",
      "step:1448,train_loss:0.023305214941501617,train_acc:0.9977678656578064\n",
      "step:1449,train_loss:0.02009235881268978,train_acc:0.9970238208770752\n",
      "step:1450,train_loss:0.027620533481240273,train_acc:0.9933035969734192\n",
      "val_acc:0.9982638955116272\n",
      "step:1451,train_loss:0.01682737097144127,train_acc:0.9985119104385376\n",
      "step:1452,train_loss:0.03943547606468201,train_acc:0.988095223903656\n",
      "step:1453,train_loss:0.02159610576927662,train_acc:0.9970238208770752\n",
      "step:1454,train_loss:0.022775903344154358,train_acc:0.9955357313156128\n",
      "step:1455,train_loss:0.020859086886048317,train_acc:0.9955357313156128\n",
      "step:1456,train_loss:0.027689434587955475,train_acc:0.9947916865348816\n",
      "step:1457,train_loss:0.01380995474755764,train_acc:0.9992559552192688\n",
      "step:1458,train_loss:0.01827375963330269,train_acc:0.9992559552192688\n",
      "step:1459,train_loss:0.025754312053322792,train_acc:0.992559552192688\n",
      "step:1460,train_loss:0.015281333588063717,train_acc:0.9977678656578064\n",
      "step:1461,train_loss:0.023173734545707703,train_acc:0.9970238208770752\n",
      "step:1462,train_loss:0.01874648593366146,train_acc:0.9970238208770752\n",
      "step:1463,train_loss:0.021566834300756454,train_acc:0.9970238208770752\n",
      "step:1464,train_loss:0.022463491186499596,train_acc:0.9947916865348816\n",
      "step:1465,train_loss:0.020074980333447456,train_acc:0.9970238208770752\n",
      "step:1466,train_loss:0.019361279904842377,train_acc:0.9970238208770752\n",
      "step:1467,train_loss:0.025908978655934334,train_acc:0.9910714030265808\n",
      "step:1468,train_loss:0.02226904034614563,train_acc:0.9940476417541504\n",
      "step:1469,train_loss:0.02966386452317238,train_acc:0.9947916865348816\n",
      "step:1470,train_loss:0.02633126638829708,train_acc:0.992559552192688\n",
      "step:1471,train_loss:0.020706452429294586,train_acc:0.9970238208770752\n",
      "step:1472,train_loss:0.02016487345099449,train_acc:0.9977678656578064\n",
      "step:1473,train_loss:0.02645587921142578,train_acc:0.9933035969734192\n",
      "step:1474,train_loss:0.014664946123957634,train_acc:0.9977678656578064\n",
      "step:1475,train_loss:0.016496529802680016,train_acc:0.9992559552192688\n",
      "step:1476,train_loss:0.019263386726379395,train_acc:0.9985119104385376\n",
      "step:1477,train_loss:0.031286709010601044,train_acc:0.9933035969734192\n",
      "step:1478,train_loss:0.022355088964104652,train_acc:0.9977678656578064\n",
      "step:1479,train_loss:0.020301776006817818,train_acc:0.9970238208770752\n",
      "step:1480,train_loss:0.026862746104598045,train_acc:0.992559552192688\n",
      "step:1481,train_loss:0.01971437782049179,train_acc:0.9947916865348816\n",
      "step:1482,train_loss:0.014699702151119709,train_acc:0.9977678656578064\n",
      "step:1483,train_loss:0.02363976463675499,train_acc:0.9933035969734192\n",
      "step:1484,train_loss:0.019625766202807426,train_acc:0.9955357313156128\n",
      "step:1485,train_loss:0.021569211035966873,train_acc:0.9977678656578064\n",
      "step:1486,train_loss:0.022139092907309532,train_acc:0.996279776096344\n",
      "step:1487,train_loss:0.025971582159399986,train_acc:0.9933035969734192\n",
      "step:1488,train_loss:0.020919745787978172,train_acc:0.9970238208770752\n",
      "step:1489,train_loss:0.016022389754652977,train_acc:0.9977678656578064\n",
      "step:1490,train_loss:0.023927731439471245,train_acc:0.9955357313156128\n",
      "step:1491,train_loss:0.017262861132621765,train_acc:0.9970238208770752\n",
      "step:1492,train_loss:0.01759842038154602,train_acc:0.996279776096344\n",
      "step:1493,train_loss:0.022228196263313293,train_acc:0.9955357313156128\n",
      "step:1494,train_loss:0.0198659785091877,train_acc:0.9970238208770752\n",
      "step:1495,train_loss:0.023475605994462967,train_acc:0.9933035969734192\n",
      "step:1496,train_loss:0.03465815633535385,train_acc:0.9903273582458496\n",
      "step:1497,train_loss:0.035079944878816605,train_acc:0.9888392686843872\n",
      "step:1498,train_loss:0.019854258745908737,train_acc:0.996279776096344\n",
      "step:1499,train_loss:0.015055341646075249,train_acc:1.0\n",
      "step:1500,train_loss:0.028107335790991783,train_acc:0.9903273582458496\n",
      "val_acc:0.9985119104385376\n",
      "step:1501,train_loss:0.017494559288024902,train_acc:0.996279776096344\n",
      "step:1502,train_loss:0.013711826875805855,train_acc:1.0\n",
      "step:1503,train_loss:0.015054984018206596,train_acc:1.0\n",
      "step:1504,train_loss:0.017601583153009415,train_acc:0.9955357313156128\n",
      "step:1505,train_loss:0.013161920011043549,train_acc:0.9992559552192688\n",
      "step:1506,train_loss:0.013929210603237152,train_acc:0.9985119104385376\n",
      "step:1507,train_loss:0.024414924904704094,train_acc:0.9933035969734192\n",
      "step:1508,train_loss:0.021475229412317276,train_acc:0.9970238208770752\n",
      "step:1509,train_loss:0.020865801721811295,train_acc:0.9977678656578064\n",
      "step:1510,train_loss:0.02377898432314396,train_acc:0.9977678656578064\n",
      "step:1511,train_loss:0.019683407619595528,train_acc:0.9955357313156128\n",
      "step:1512,train_loss:0.019191499799489975,train_acc:0.9992559552192688\n",
      "step:1513,train_loss:0.018608830869197845,train_acc:0.9985119104385376\n",
      "step:1514,train_loss:0.016041649505496025,train_acc:0.9992559552192688\n",
      "step:1515,train_loss:0.023909524083137512,train_acc:0.9947916865348816\n",
      "step:1516,train_loss:0.017816653475165367,train_acc:0.996279776096344\n",
      "step:1517,train_loss:0.017201459035277367,train_acc:0.9985119104385376\n",
      "step:1518,train_loss:0.021474411711096764,train_acc:0.9947916865348816\n",
      "step:1519,train_loss:0.014563200064003468,train_acc:0.9985119104385376\n",
      "step:1520,train_loss:0.025000134482979774,train_acc:0.9933035969734192\n",
      "step:1521,train_loss:0.01836174726486206,train_acc:0.9977678656578064\n",
      "step:1522,train_loss:0.017346370965242386,train_acc:0.996279776096344\n",
      "step:1523,train_loss:0.021131649613380432,train_acc:0.9955357313156128\n",
      "step:1524,train_loss:0.01664682850241661,train_acc:0.996279776096344\n",
      "step:1525,train_loss:0.017490841448307037,train_acc:0.996279776096344\n",
      "step:1526,train_loss:0.014547474682331085,train_acc:0.9985119104385376\n",
      "step:1527,train_loss:0.015725931152701378,train_acc:0.9985119104385376\n",
      "step:1528,train_loss:0.03405020758509636,train_acc:0.991815447807312\n",
      "step:1529,train_loss:0.017835285514593124,train_acc:0.9955357313156128\n",
      "step:1530,train_loss:0.02227984368801117,train_acc:0.9970238208770752\n",
      "step:1531,train_loss:0.01774820126593113,train_acc:0.9977678656578064\n",
      "step:1532,train_loss:0.01691260002553463,train_acc:0.9955357313156128\n",
      "step:1533,train_loss:0.03718180954456329,train_acc:0.988095223903656\n",
      "step:1534,train_loss:0.02248295582830906,train_acc:0.9970238208770752\n",
      "step:1535,train_loss:0.017762282863259315,train_acc:0.9947916865348816\n",
      "step:1536,train_loss:0.01609356328845024,train_acc:0.9970238208770752\n",
      "step:1537,train_loss:0.01856931298971176,train_acc:0.9977678656578064\n",
      "step:1538,train_loss:0.024204779416322708,train_acc:0.9970238208770752\n",
      "step:1539,train_loss:0.01812274008989334,train_acc:0.9985119104385376\n",
      "step:1540,train_loss:0.01828829199075699,train_acc:0.9970238208770752\n",
      "step:1541,train_loss:0.018215414136648178,train_acc:0.9977678656578064\n",
      "step:1542,train_loss:0.01373063214123249,train_acc:0.9992559552192688\n",
      "step:1543,train_loss:0.02445477619767189,train_acc:0.9955357313156128\n",
      "step:1544,train_loss:0.014320586808025837,train_acc:0.9985119104385376\n",
      "step:1545,train_loss:0.014766762964427471,train_acc:1.0\n",
      "step:1546,train_loss:0.02038773149251938,train_acc:0.9977678656578064\n",
      "step:1547,train_loss:0.024711623787879944,train_acc:0.9940476417541504\n",
      "step:1548,train_loss:0.018341941758990288,train_acc:0.9977678656578064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1549,train_loss:0.018229082226753235,train_acc:0.9970238208770752\n",
      "step:1550,train_loss:0.018785377964377403,train_acc:0.9955357313156128\n",
      "val_acc:0.9997519850730896\n",
      "step:1551,train_loss:0.020109692588448524,train_acc:0.9970238208770752\n",
      "step:1552,train_loss:0.028373729437589645,train_acc:0.9903273582458496\n",
      "step:1553,train_loss:0.015559082850813866,train_acc:0.9985119104385376\n",
      "step:1554,train_loss:0.023119712248444557,train_acc:0.992559552192688\n",
      "step:1555,train_loss:0.025789115577936172,train_acc:0.9947916865348816\n",
      "step:1556,train_loss:0.021068040281534195,train_acc:0.9955357313156128\n",
      "step:1557,train_loss:0.020614206790924072,train_acc:0.9970238208770752\n",
      "step:1558,train_loss:0.022938385605812073,train_acc:0.9947916865348816\n",
      "step:1559,train_loss:0.0197361558675766,train_acc:0.996279776096344\n",
      "step:1560,train_loss:0.016745300963521004,train_acc:0.9985119104385376\n",
      "step:1561,train_loss:0.01822882890701294,train_acc:0.9970238208770752\n",
      "step:1562,train_loss:0.016875561326742172,train_acc:0.9970238208770752\n",
      "step:1563,train_loss:0.01767686940729618,train_acc:0.9955357313156128\n",
      "step:1564,train_loss:0.021726086735725403,train_acc:0.9955357313156128\n",
      "step:1565,train_loss:0.018466783687472343,train_acc:0.9977678656578064\n",
      "step:1566,train_loss:0.020715372636914253,train_acc:0.996279776096344\n",
      "step:1567,train_loss:0.012581342831254005,train_acc:1.0\n",
      "step:1568,train_loss:0.024134641513228416,train_acc:0.996279776096344\n",
      "step:1569,train_loss:0.02892290987074375,train_acc:0.992559552192688\n",
      "step:1570,train_loss:0.013948461972177029,train_acc:0.9985119104385376\n",
      "step:1571,train_loss:0.022537676617503166,train_acc:0.9970238208770752\n",
      "step:1572,train_loss:0.019172262400388718,train_acc:0.996279776096344\n",
      "step:1573,train_loss:0.015426655299961567,train_acc:0.9977678656578064\n",
      "step:1574,train_loss:0.013344685547053814,train_acc:0.9985119104385376\n",
      "step:1575,train_loss:0.012782406061887741,train_acc:0.9992559552192688\n",
      "step:1576,train_loss:0.01326013170182705,train_acc:0.9992559552192688\n",
      "step:1577,train_loss:0.02300923690199852,train_acc:0.9955357313156128\n",
      "step:1578,train_loss:0.01791088841855526,train_acc:0.9970238208770752\n",
      "step:1579,train_loss:0.020370032638311386,train_acc:0.996279776096344\n",
      "step:1580,train_loss:0.015046786516904831,train_acc:0.9985119104385376\n",
      "step:1581,train_loss:0.0122140571475029,train_acc:1.0\n",
      "step:1582,train_loss:0.014824889600276947,train_acc:0.9977678656578064\n",
      "step:1583,train_loss:0.014058345928788185,train_acc:0.9977678656578064\n",
      "step:1584,train_loss:0.013719930313527584,train_acc:1.0\n",
      "step:1585,train_loss:0.0183109138160944,train_acc:0.996279776096344\n",
      "step:1586,train_loss:0.01727304793894291,train_acc:0.9985119104385376\n",
      "step:1587,train_loss:0.011684437282383442,train_acc:0.9985119104385376\n",
      "step:1588,train_loss:0.011399690993130207,train_acc:0.9992559552192688\n",
      "step:1589,train_loss:0.022876104339957237,train_acc:0.996279776096344\n",
      "step:1590,train_loss:0.01193875540047884,train_acc:0.9992559552192688\n",
      "step:1591,train_loss:0.014865696430206299,train_acc:0.9970238208770752\n",
      "step:1592,train_loss:0.01753947325050831,train_acc:0.9977678656578064\n",
      "step:1593,train_loss:0.022501682862639427,train_acc:0.9940476417541504\n",
      "step:1594,train_loss:0.017965801060199738,train_acc:0.9955357313156128\n",
      "step:1595,train_loss:0.024357613176107407,train_acc:0.9955357313156128\n",
      "step:1596,train_loss:0.02233698219060898,train_acc:0.996279776096344\n",
      "step:1597,train_loss:0.027217384427785873,train_acc:0.9910714030265808\n",
      "step:1598,train_loss:0.01920182630419731,train_acc:0.9977678656578064\n",
      "step:1599,train_loss:0.017208606004714966,train_acc:0.9985119104385376\n",
      "step:1600,train_loss:0.04195651784539223,train_acc:0.9836309552192688\n",
      "val_acc:0.998759925365448\n",
      "step:1601,train_loss:0.022147858515381813,train_acc:0.9955357313156128\n",
      "step:1602,train_loss:0.014601108618080616,train_acc:0.996279776096344\n",
      "step:1603,train_loss:0.014130736701190472,train_acc:0.9977678656578064\n",
      "step:1604,train_loss:0.012406990863382816,train_acc:0.9992559552192688\n",
      "step:1605,train_loss:0.015279128216207027,train_acc:0.9985119104385376\n",
      "step:1606,train_loss:0.014877661131322384,train_acc:0.9992559552192688\n",
      "step:1607,train_loss:0.019860265776515007,train_acc:0.9940476417541504\n",
      "step:1608,train_loss:0.013473058119416237,train_acc:0.9977678656578064\n",
      "step:1609,train_loss:0.022456560283899307,train_acc:0.9947916865348816\n",
      "step:1610,train_loss:0.01697300188243389,train_acc:0.9977678656578064\n",
      "step:1611,train_loss:0.02387714385986328,train_acc:0.9955357313156128\n",
      "step:1612,train_loss:0.017759643495082855,train_acc:0.9977678656578064\n",
      "step:1613,train_loss:0.019212933257222176,train_acc:0.9985119104385376\n",
      "step:1614,train_loss:0.014881874434649944,train_acc:0.9985119104385376\n",
      "step:1615,train_loss:0.015014681033790112,train_acc:0.9977678656578064\n",
      "step:1616,train_loss:0.022699858993291855,train_acc:0.9970238208770752\n",
      "step:1617,train_loss:0.01615440472960472,train_acc:0.9970238208770752\n",
      "step:1618,train_loss:0.014471249654889107,train_acc:0.9977678656578064\n",
      "step:1619,train_loss:0.01753256469964981,train_acc:0.9985119104385376\n",
      "step:1620,train_loss:0.028956850990653038,train_acc:0.991815447807312\n",
      "step:1621,train_loss:0.015543114393949509,train_acc:0.9985119104385376\n",
      "step:1622,train_loss:0.020124826580286026,train_acc:0.9955357313156128\n",
      "step:1623,train_loss:0.024456510320305824,train_acc:0.9955357313156128\n",
      "step:1624,train_loss:0.012248971499502659,train_acc:0.9992559552192688\n",
      "step:1625,train_loss:0.01727977581322193,train_acc:0.9977678656578064\n",
      "step:1626,train_loss:0.016021067276597023,train_acc:0.9977678656578064\n",
      "step:1627,train_loss:0.01895439624786377,train_acc:0.9955357313156128\n",
      "step:1628,train_loss:0.016078434884548187,train_acc:0.9970238208770752\n",
      "step:1629,train_loss:0.012645366601645947,train_acc:0.9985119104385376\n",
      "step:1630,train_loss:0.016064686700701714,train_acc:0.9970238208770752\n",
      "step:1631,train_loss:0.017063235864043236,train_acc:0.9992559552192688\n",
      "step:1632,train_loss:0.016677221283316612,train_acc:0.9970238208770752\n",
      "step:1633,train_loss:0.010897998698055744,train_acc:0.9977678656578064\n",
      "step:1634,train_loss:0.0098034692928195,train_acc:1.0\n",
      "step:1635,train_loss:0.018375759944319725,train_acc:0.9970238208770752\n",
      "step:1636,train_loss:0.015881294384598732,train_acc:0.9977678656578064\n",
      "step:1637,train_loss:0.032383032143116,train_acc:0.9910714030265808\n",
      "step:1638,train_loss:0.014675137586891651,train_acc:0.9977678656578064\n",
      "step:1639,train_loss:0.013860984705388546,train_acc:0.9977678656578064\n",
      "step:1640,train_loss:0.015702739357948303,train_acc:0.996279776096344\n",
      "step:1641,train_loss:0.020692160353064537,train_acc:0.9955357313156128\n",
      "step:1642,train_loss:0.016618778929114342,train_acc:0.9977678656578064\n",
      "step:1643,train_loss:0.01515830960124731,train_acc:0.9992559552192688\n",
      "step:1644,train_loss:0.024440240114927292,train_acc:0.9947916865348816\n",
      "step:1645,train_loss:0.013631622307002544,train_acc:0.9992559552192688\n",
      "step:1646,train_loss:0.018877267837524414,train_acc:0.9955357313156128\n",
      "step:1647,train_loss:0.021375607699155807,train_acc:0.9970238208770752\n",
      "step:1648,train_loss:0.014278609305620193,train_acc:0.9977678656578064\n",
      "step:1649,train_loss:0.014345323666930199,train_acc:0.9977678656578064\n",
      "step:1650,train_loss:0.01770496740937233,train_acc:0.996279776096344\n",
      "val_acc:0.998759925365448\n",
      "step:1651,train_loss:0.012566124089062214,train_acc:0.9985119104385376\n",
      "step:1652,train_loss:0.01741722598671913,train_acc:0.9977678656578064\n",
      "step:1653,train_loss:0.015732916072010994,train_acc:0.9970238208770752\n",
      "step:1654,train_loss:0.024791890755295753,train_acc:0.992559552192688\n",
      "step:1655,train_loss:0.012273934669792652,train_acc:0.9977678656578064\n",
      "step:1656,train_loss:0.016674300655722618,train_acc:0.9970238208770752\n",
      "step:1657,train_loss:0.013430234976112843,train_acc:0.9992559552192688\n",
      "step:1658,train_loss:0.014044945128262043,train_acc:0.9985119104385376\n",
      "step:1659,train_loss:0.015704182907938957,train_acc:0.9977678656578064\n",
      "step:1660,train_loss:0.016466673463582993,train_acc:0.9977678656578064\n",
      "step:1661,train_loss:0.010043158195912838,train_acc:0.9992559552192688\n",
      "step:1662,train_loss:0.01384594477713108,train_acc:0.9977678656578064\n",
      "step:1663,train_loss:0.03059278428554535,train_acc:0.992559552192688\n",
      "step:1664,train_loss:0.01381666585803032,train_acc:0.9985119104385376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1665,train_loss:0.01603863388299942,train_acc:0.9955357313156128\n",
      "step:1666,train_loss:0.014630276709794998,train_acc:0.9977678656578064\n",
      "step:1667,train_loss:0.015089582651853561,train_acc:0.9970238208770752\n",
      "step:1668,train_loss:0.00930013321340084,train_acc:1.0\n",
      "step:1669,train_loss:0.013643796555697918,train_acc:0.9985119104385376\n",
      "step:1670,train_loss:0.020120084285736084,train_acc:0.9970238208770752\n",
      "step:1671,train_loss:0.012728726491332054,train_acc:0.9992559552192688\n",
      "step:1672,train_loss:0.020461896434426308,train_acc:0.9970238208770752\n",
      "step:1673,train_loss:0.018060533329844475,train_acc:0.9970238208770752\n",
      "step:1674,train_loss:0.013061873614788055,train_acc:1.0\n",
      "step:1675,train_loss:0.018032129853963852,train_acc:0.9970238208770752\n",
      "step:1676,train_loss:0.02022217959165573,train_acc:0.9947916865348816\n",
      "step:1677,train_loss:0.01596381887793541,train_acc:0.9970238208770752\n",
      "step:1678,train_loss:0.011782304383814335,train_acc:1.0\n",
      "step:1679,train_loss:0.012011511251330376,train_acc:0.9985119104385376\n",
      "step:1680,train_loss:0.014512053690850735,train_acc:0.9977678656578064\n",
      "step:1681,train_loss:0.013577272184193134,train_acc:0.9977678656578064\n",
      "step:1682,train_loss:0.013343933038413525,train_acc:0.9985119104385376\n",
      "step:1683,train_loss:0.015521149151027203,train_acc:0.9985119104385376\n",
      "step:1684,train_loss:0.020347686484456062,train_acc:0.996279776096344\n",
      "step:1685,train_loss:0.020539233461022377,train_acc:0.9940476417541504\n",
      "step:1686,train_loss:0.01351817138493061,train_acc:0.9985119104385376\n",
      "step:1687,train_loss:0.0146264573559165,train_acc:0.996279776096344\n",
      "step:1688,train_loss:0.026648743078112602,train_acc:0.992559552192688\n",
      "step:1689,train_loss:0.01547338254749775,train_acc:0.9985119104385376\n",
      "step:1690,train_loss:0.008576705120503902,train_acc:0.9992559552192688\n",
      "step:1691,train_loss:0.02099422924220562,train_acc:0.9933035969734192\n",
      "step:1692,train_loss:0.013682727701961994,train_acc:0.9985119104385376\n",
      "step:1693,train_loss:0.011857954785227776,train_acc:0.9985119104385376\n",
      "step:1694,train_loss:0.020414508879184723,train_acc:0.9947916865348816\n",
      "step:1695,train_loss:0.02005082555115223,train_acc:0.9955357313156128\n",
      "step:1696,train_loss:0.013859385624527931,train_acc:0.996279776096344\n",
      "step:1697,train_loss:0.01562468521296978,train_acc:0.996279776096344\n",
      "step:1698,train_loss:0.023441167548298836,train_acc:0.992559552192688\n",
      "step:1699,train_loss:0.01658700592815876,train_acc:0.9977678656578064\n",
      "step:1700,train_loss:0.01832730509340763,train_acc:0.9955357313156128\n",
      "val_acc:0.998759925365448\n",
      "step:1701,train_loss:0.013251282274723053,train_acc:0.9985119104385376\n",
      "step:1702,train_loss:0.02302573062479496,train_acc:0.9947916865348816\n",
      "step:1703,train_loss:0.015052320435643196,train_acc:0.9985119104385376\n",
      "step:1704,train_loss:0.015484143979847431,train_acc:0.9970238208770752\n",
      "step:1705,train_loss:0.01877211406826973,train_acc:0.996279776096344\n",
      "step:1706,train_loss:0.021340515464544296,train_acc:0.9955357313156128\n",
      "step:1707,train_loss:0.025666648522019386,train_acc:0.9910714030265808\n",
      "step:1708,train_loss:0.02136552333831787,train_acc:0.9955357313156128\n",
      "step:1709,train_loss:0.01532702799886465,train_acc:0.9985119104385376\n",
      "step:1710,train_loss:0.012981911189854145,train_acc:0.9992559552192688\n",
      "step:1711,train_loss:0.01651957258582115,train_acc:0.9970238208770752\n",
      "step:1712,train_loss:0.012302407063543797,train_acc:0.9992559552192688\n",
      "step:1713,train_loss:0.014406757429242134,train_acc:1.0\n",
      "step:1714,train_loss:0.015334714204072952,train_acc:0.996279776096344\n",
      "step:1715,train_loss:0.017249127849936485,train_acc:0.996279776096344\n",
      "step:1716,train_loss:0.014297124929726124,train_acc:0.9977678656578064\n",
      "step:1717,train_loss:0.012514784000813961,train_acc:0.9985119104385376\n",
      "step:1718,train_loss:0.017868850380182266,train_acc:0.9970238208770752\n",
      "step:1719,train_loss:0.023716513067483902,train_acc:0.9933035969734192\n",
      "step:1720,train_loss:0.01584763079881668,train_acc:0.9955357313156128\n",
      "step:1721,train_loss:0.0141138955950737,train_acc:0.9977678656578064\n",
      "step:1722,train_loss:0.012639790773391724,train_acc:0.9985119104385376\n",
      "step:1723,train_loss:0.018967119976878166,train_acc:0.996279776096344\n",
      "step:1724,train_loss:0.016582118347287178,train_acc:0.9970238208770752\n",
      "step:1725,train_loss:0.016064604744315147,train_acc:0.996279776096344\n",
      "step:1726,train_loss:0.014924957416951656,train_acc:0.996279776096344\n",
      "step:1727,train_loss:0.02316868118941784,train_acc:0.992559552192688\n",
      "step:1728,train_loss:0.012168044224381447,train_acc:0.9977678656578064\n",
      "step:1729,train_loss:0.025435419753193855,train_acc:0.992559552192688\n",
      "step:1730,train_loss:0.015492020174860954,train_acc:0.9977678656578064\n",
      "step:1731,train_loss:0.018320253118872643,train_acc:0.9955357313156128\n",
      "step:1732,train_loss:0.01368100568652153,train_acc:0.9977678656578064\n",
      "step:1733,train_loss:0.024356478825211525,train_acc:0.9947916865348816\n",
      "step:1734,train_loss:0.01519897859543562,train_acc:0.9985119104385376\n",
      "step:1735,train_loss:0.012522302567958832,train_acc:0.9985119104385376\n",
      "step:1736,train_loss:0.013233098201453686,train_acc:0.9970238208770752\n",
      "step:1737,train_loss:0.01653200574219227,train_acc:0.9977678656578064\n",
      "step:1738,train_loss:0.013479102402925491,train_acc:0.9970238208770752\n",
      "step:1739,train_loss:0.023770205676555634,train_acc:0.992559552192688\n",
      "step:1740,train_loss:0.012765183113515377,train_acc:0.9985119104385376\n",
      "step:1741,train_loss:0.016232972964644432,train_acc:0.9977678656578064\n",
      "step:1742,train_loss:0.012228730134665966,train_acc:0.9985119104385376\n",
      "step:1743,train_loss:0.011764895170927048,train_acc:0.9985119104385376\n",
      "step:1744,train_loss:0.010974826291203499,train_acc:0.9992559552192688\n",
      "step:1745,train_loss:0.015501165762543678,train_acc:0.996279776096344\n",
      "step:1746,train_loss:0.009528645314276218,train_acc:1.0\n",
      "step:1747,train_loss:0.012555239722132683,train_acc:0.996279776096344\n",
      "step:1748,train_loss:0.015182421542704105,train_acc:0.9947916865348816\n",
      "step:1749,train_loss:0.016348067671060562,train_acc:0.9977678656578064\n",
      "step:1750,train_loss:0.016947345808148384,train_acc:0.9955357313156128\n",
      "val_acc:0.9997519850730896\n",
      "step:1751,train_loss:0.018253525719046593,train_acc:0.996279776096344\n",
      "step:1752,train_loss:0.017608841881155968,train_acc:0.9977678656578064\n",
      "step:1753,train_loss:0.012245877645909786,train_acc:0.9985119104385376\n",
      "step:1754,train_loss:0.01872890256345272,train_acc:0.996279776096344\n",
      "step:1755,train_loss:0.010687379166483879,train_acc:1.0\n",
      "step:1756,train_loss:0.0159490704536438,train_acc:0.9977678656578064\n",
      "step:1757,train_loss:0.01543627493083477,train_acc:0.9970238208770752\n",
      "step:1758,train_loss:0.01435749139636755,train_acc:0.9992559552192688\n",
      "step:1759,train_loss:0.020513510331511497,train_acc:0.9947916865348816\n",
      "step:1760,train_loss:0.023515528067946434,train_acc:0.9955357313156128\n",
      "step:1761,train_loss:0.016837742179632187,train_acc:0.9970238208770752\n",
      "step:1762,train_loss:0.009517841041088104,train_acc:1.0\n",
      "step:1763,train_loss:0.015649184584617615,train_acc:0.9992559552192688\n",
      "step:1764,train_loss:0.013271849602460861,train_acc:0.9977678656578064\n",
      "step:1765,train_loss:0.01501647662371397,train_acc:0.9992559552192688\n",
      "step:1766,train_loss:0.017351826652884483,train_acc:0.9955357313156128\n",
      "step:1767,train_loss:0.014078468084335327,train_acc:0.9977678656578064\n",
      "step:1768,train_loss:0.017325827851891518,train_acc:0.9977678656578064\n",
      "step:1769,train_loss:0.027003690600395203,train_acc:0.9933035969734192\n",
      "step:1770,train_loss:0.012229331769049168,train_acc:0.9985119104385376\n",
      "step:1771,train_loss:0.015447732992470264,train_acc:0.9977678656578064\n",
      "step:1772,train_loss:0.011376984417438507,train_acc:1.0\n",
      "step:1773,train_loss:0.012504978105425835,train_acc:0.9977678656578064\n",
      "step:1774,train_loss:0.02302299439907074,train_acc:0.9947916865348816\n",
      "step:1775,train_loss:0.012851959094405174,train_acc:0.9992559552192688\n",
      "step:1776,train_loss:0.018716545775532722,train_acc:0.996279776096344\n",
      "step:1777,train_loss:0.015438868664205074,train_acc:0.9985119104385376\n",
      "step:1778,train_loss:0.02323727495968342,train_acc:0.992559552192688\n",
      "step:1779,train_loss:0.01874847523868084,train_acc:0.9955357313156128\n",
      "step:1780,train_loss:0.012969525530934334,train_acc:0.9985119104385376\n",
      "step:1781,train_loss:0.018037645146250725,train_acc:0.9940476417541504\n",
      "step:1782,train_loss:0.012774132192134857,train_acc:0.9977678656578064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1783,train_loss:0.019558873027563095,train_acc:0.9940476417541504\n",
      "step:1784,train_loss:0.018673868849873543,train_acc:0.9940476417541504\n",
      "step:1785,train_loss:0.019704077392816544,train_acc:0.996279776096344\n",
      "step:1786,train_loss:0.016718914732336998,train_acc:0.9970238208770752\n",
      "step:1787,train_loss:0.015332406386733055,train_acc:0.9947916865348816\n",
      "step:1788,train_loss:0.013912122696638107,train_acc:0.9985119104385376\n",
      "step:1789,train_loss:0.013836230151355267,train_acc:0.9985119104385376\n",
      "step:1790,train_loss:0.0119326738640666,train_acc:0.9970238208770752\n",
      "step:1791,train_loss:0.012093739584088326,train_acc:0.9977678656578064\n",
      "step:1792,train_loss:0.02107827737927437,train_acc:0.9947916865348816\n",
      "step:1793,train_loss:0.01873374916613102,train_acc:0.9955357313156128\n",
      "step:1794,train_loss:0.03465870022773743,train_acc:0.9895833134651184\n",
      "step:1795,train_loss:0.019019385799765587,train_acc:0.9955357313156128\n",
      "step:1796,train_loss:0.01895296387374401,train_acc:0.9955357313156128\n",
      "step:1797,train_loss:0.011490536853671074,train_acc:0.9992559552192688\n",
      "step:1798,train_loss:0.017469709739089012,train_acc:0.9977678656578064\n",
      "step:1799,train_loss:0.011628413572907448,train_acc:0.9985119104385376\n",
      "step:1800,train_loss:0.014309111051261425,train_acc:0.9970238208770752\n",
      "val_acc:0.9980158805847168\n",
      "step:1801,train_loss:0.01874413713812828,train_acc:0.9970238208770752\n",
      "step:1802,train_loss:0.014382059685885906,train_acc:0.9970238208770752\n",
      "step:1803,train_loss:0.012613792903721333,train_acc:0.9970238208770752\n",
      "step:1804,train_loss:0.014234954491257668,train_acc:0.9977678656578064\n",
      "step:1805,train_loss:0.01589815691113472,train_acc:0.9970238208770752\n",
      "step:1806,train_loss:0.01446598768234253,train_acc:0.996279776096344\n",
      "step:1807,train_loss:0.012475283816456795,train_acc:0.9985119104385376\n",
      "step:1808,train_loss:0.021535178646445274,train_acc:0.9940476417541504\n",
      "step:1809,train_loss:0.024878690019249916,train_acc:0.992559552192688\n",
      "step:1810,train_loss:0.010849632322788239,train_acc:0.9977678656578064\n",
      "step:1811,train_loss:0.016652893275022507,train_acc:0.9955357313156128\n",
      "step:1812,train_loss:0.01913856714963913,train_acc:0.9933035969734192\n",
      "step:1813,train_loss:0.015800124034285545,train_acc:0.9977678656578064\n",
      "step:1814,train_loss:0.012051115743815899,train_acc:0.9992559552192688\n",
      "step:1815,train_loss:0.02057461254298687,train_acc:0.9977678656578064\n",
      "step:1816,train_loss:0.011889336630702019,train_acc:0.9992559552192688\n",
      "step:1817,train_loss:0.014262218959629536,train_acc:0.9977678656578064\n",
      "step:1818,train_loss:0.01351698487997055,train_acc:0.9977678656578064\n",
      "step:1819,train_loss:0.019294841215014458,train_acc:0.996279776096344\n",
      "step:1820,train_loss:0.012962301261723042,train_acc:0.9992559552192688\n",
      "step:1821,train_loss:0.01466040126979351,train_acc:0.9955357313156128\n",
      "step:1822,train_loss:0.013817036524415016,train_acc:0.9985119104385376\n",
      "step:1823,train_loss:0.01942478120326996,train_acc:0.9940476417541504\n",
      "step:1824,train_loss:0.013909053057432175,train_acc:0.9977678656578064\n",
      "step:1825,train_loss:0.016229307278990746,train_acc:0.9970238208770752\n",
      "step:1826,train_loss:0.023190150037407875,train_acc:0.9985119104385376\n",
      "step:1827,train_loss:0.010400238446891308,train_acc:0.9977678656578064\n",
      "step:1828,train_loss:0.020871758460998535,train_acc:0.9947916865348816\n",
      "step:1829,train_loss:0.01960018463432789,train_acc:0.9970238208770752\n",
      "step:1830,train_loss:0.011624295264482498,train_acc:0.9977678656578064\n",
      "step:1831,train_loss:0.023161880671977997,train_acc:0.9933035969734192\n",
      "step:1832,train_loss:0.016149360686540604,train_acc:0.996279776096344\n",
      "step:1833,train_loss:0.012132500298321247,train_acc:0.9970238208770752\n",
      "step:1834,train_loss:0.0113539919257164,train_acc:1.0\n",
      "step:1835,train_loss:0.010370595380663872,train_acc:0.9992559552192688\n",
      "step:1836,train_loss:0.01261014211922884,train_acc:0.9992559552192688\n",
      "step:1837,train_loss:0.012561862356960773,train_acc:0.9977678656578064\n",
      "step:1838,train_loss:0.026047060266137123,train_acc:0.9940476417541504\n",
      "step:1839,train_loss:0.010890793055295944,train_acc:0.9985119104385376\n",
      "step:1840,train_loss:0.016469677910208702,train_acc:0.9977678656578064\n",
      "step:1841,train_loss:0.011224625632166862,train_acc:0.9985119104385376\n",
      "step:1842,train_loss:0.014181548729538918,train_acc:0.9977678656578064\n",
      "step:1843,train_loss:0.013996669091284275,train_acc:0.9977678656578064\n",
      "step:1844,train_loss:0.02408386766910553,train_acc:0.9940476417541504\n",
      "step:1845,train_loss:0.016125289723277092,train_acc:0.9992559552192688\n",
      "step:1846,train_loss:0.011845867149531841,train_acc:0.9992559552192688\n",
      "step:1847,train_loss:0.021784793585538864,train_acc:0.9940476417541504\n",
      "step:1848,train_loss:0.017853131517767906,train_acc:0.9977678656578064\n",
      "step:1849,train_loss:0.020329641178250313,train_acc:0.9955357313156128\n",
      "step:1850,train_loss:0.01944367028772831,train_acc:0.9970238208770752\n",
      "val_acc:0.9982638955116272\n",
      "step:1851,train_loss:0.0259910449385643,train_acc:0.991815447807312\n",
      "step:1852,train_loss:0.025150829926133156,train_acc:0.9947916865348816\n",
      "step:1853,train_loss:0.0201356690376997,train_acc:0.9947916865348816\n",
      "step:1854,train_loss:0.01487886905670166,train_acc:0.996279776096344\n",
      "step:1855,train_loss:0.012120268307626247,train_acc:0.9977678656578064\n",
      "step:1856,train_loss:0.021408742293715477,train_acc:0.9940476417541504\n",
      "step:1857,train_loss:0.01035244669765234,train_acc:0.9985119104385376\n",
      "step:1858,train_loss:0.026732495054602623,train_acc:0.992559552192688\n",
      "step:1859,train_loss:0.020178236067295074,train_acc:0.9940476417541504\n",
      "step:1860,train_loss:0.012127263471484184,train_acc:0.9992559552192688\n",
      "step:1861,train_loss:0.023344891145825386,train_acc:0.9933035969734192\n",
      "step:1862,train_loss:0.014526903629302979,train_acc:0.9992559552192688\n",
      "step:1863,train_loss:0.023676052689552307,train_acc:0.991815447807312\n",
      "step:1864,train_loss:0.022068936377763748,train_acc:0.9940476417541504\n",
      "step:1865,train_loss:0.014131042174994946,train_acc:0.9985119104385376\n",
      "step:1866,train_loss:0.026414206251502037,train_acc:0.991815447807312\n",
      "step:1867,train_loss:0.020962709560990334,train_acc:0.9940476417541504\n",
      "step:1868,train_loss:0.013725774362683296,train_acc:0.9977678656578064\n",
      "step:1869,train_loss:0.01333201490342617,train_acc:0.9985119104385376\n",
      "step:1870,train_loss:0.018462929874658585,train_acc:0.9970238208770752\n",
      "step:1871,train_loss:0.013786522671580315,train_acc:0.9977678656578064\n",
      "step:1872,train_loss:0.031762901693582535,train_acc:0.988095223903656\n",
      "step:1873,train_loss:0.011459127068519592,train_acc:1.0\n",
      "step:1874,train_loss:0.01759718917310238,train_acc:0.9977678656578064\n",
      "step:1875,train_loss:0.014797622337937355,train_acc:0.9977678656578064\n",
      "step:1876,train_loss:0.018255429342389107,train_acc:0.9955357313156128\n",
      "step:1877,train_loss:0.016116075217723846,train_acc:0.996279776096344\n",
      "step:1878,train_loss:0.027366161346435547,train_acc:0.9940476417541504\n",
      "step:1879,train_loss:0.016673129051923752,train_acc:0.9955357313156128\n",
      "step:1880,train_loss:0.016294196248054504,train_acc:0.996279776096344\n",
      "step:1881,train_loss:0.022312726825475693,train_acc:0.9940476417541504\n",
      "step:1882,train_loss:0.015292633324861526,train_acc:0.9985119104385376\n",
      "step:1883,train_loss:0.016569646075367928,train_acc:0.9970238208770752\n",
      "step:1884,train_loss:0.015521452762186527,train_acc:0.9977678656578064\n",
      "step:1885,train_loss:0.01587558165192604,train_acc:0.9977678656578064\n",
      "step:1886,train_loss:0.010559504851698875,train_acc:1.0\n",
      "step:1887,train_loss:0.01610158383846283,train_acc:0.9970238208770752\n",
      "step:1888,train_loss:0.013143328949809074,train_acc:0.9985119104385376\n",
      "step:1889,train_loss:0.01611088588833809,train_acc:0.9970238208770752\n",
      "step:1890,train_loss:0.015495218336582184,train_acc:0.9947916865348816\n",
      "step:1891,train_loss:0.018006419762969017,train_acc:0.9970238208770752\n",
      "step:1892,train_loss:0.016603508964180946,train_acc:0.996279776096344\n",
      "step:1893,train_loss:0.01831359788775444,train_acc:0.9955357313156128\n",
      "step:1894,train_loss:0.012576631270349026,train_acc:0.9992559552192688\n",
      "step:1895,train_loss:0.01251190435141325,train_acc:0.9992559552192688\n",
      "step:1896,train_loss:0.012758043594658375,train_acc:0.9970238208770752\n",
      "step:1897,train_loss:0.015845414251089096,train_acc:0.996279776096344\n",
      "step:1898,train_loss:0.014875893481075764,train_acc:0.9977678656578064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1899,train_loss:0.021114900708198547,train_acc:0.9955357313156128\n",
      "step:1900,train_loss:0.014865679666399956,train_acc:0.9970238208770752\n",
      "val_acc:0.9985119104385376\n",
      "step:1901,train_loss:0.014488719403743744,train_acc:0.9970238208770752\n",
      "step:1902,train_loss:0.024409430101513863,train_acc:0.9933035969734192\n",
      "step:1903,train_loss:0.02549808844923973,train_acc:0.991815447807312\n",
      "step:1904,train_loss:0.011206558905541897,train_acc:0.9985119104385376\n",
      "step:1905,train_loss:0.021417727693915367,train_acc:0.9947916865348816\n",
      "step:1906,train_loss:0.018741462379693985,train_acc:0.9970238208770752\n",
      "step:1907,train_loss:0.018639760091900826,train_acc:0.9970238208770752\n",
      "step:1908,train_loss:0.023745210841298103,train_acc:0.992559552192688\n",
      "step:1909,train_loss:0.013986608944833279,train_acc:0.9985119104385376\n",
      "step:1910,train_loss:0.015286012552678585,train_acc:0.9985119104385376\n",
      "step:1911,train_loss:0.032984279096126556,train_acc:0.9895833134651184\n",
      "step:1912,train_loss:0.018961111083626747,train_acc:0.9947916865348816\n",
      "step:1913,train_loss:0.0141372699290514,train_acc:0.9992559552192688\n",
      "step:1914,train_loss:0.013764852657914162,train_acc:0.9985119104385376\n",
      "step:1915,train_loss:0.01757337525486946,train_acc:0.996279776096344\n",
      "step:1916,train_loss:0.01960591971874237,train_acc:0.9933035969734192\n",
      "step:1917,train_loss:0.0189655814319849,train_acc:0.9940476417541504\n",
      "step:1918,train_loss:0.019790003076195717,train_acc:0.9940476417541504\n",
      "step:1919,train_loss:0.016973359510302544,train_acc:0.996279776096344\n",
      "step:1920,train_loss:0.020607832819223404,train_acc:0.9955357313156128\n",
      "step:1921,train_loss:0.01990668475627899,train_acc:0.9947916865348816\n",
      "step:1922,train_loss:0.015324799343943596,train_acc:0.9985119104385376\n",
      "step:1923,train_loss:0.02498468942940235,train_acc:0.9933035969734192\n",
      "step:1924,train_loss:0.024044275283813477,train_acc:0.992559552192688\n",
      "step:1925,train_loss:0.01957831159234047,train_acc:0.9940476417541504\n",
      "step:1926,train_loss:0.019647404551506042,train_acc:0.9947916865348816\n",
      "step:1927,train_loss:0.021651674062013626,train_acc:0.991815447807312\n",
      "step:1928,train_loss:0.026507627218961716,train_acc:0.9940476417541504\n",
      "step:1929,train_loss:0.014433690346777439,train_acc:0.9977678656578064\n",
      "step:1930,train_loss:0.01938742958009243,train_acc:0.9955357313156128\n",
      "step:1931,train_loss:0.0121691282838583,train_acc:0.9985119104385376\n",
      "step:1932,train_loss:0.01786990463733673,train_acc:0.9947916865348816\n",
      "step:1933,train_loss:0.010242069140076637,train_acc:0.9985119104385376\n",
      "step:1934,train_loss:0.02927209995687008,train_acc:0.9933035969734192\n",
      "step:1935,train_loss:0.016155360266566277,train_acc:0.9955357313156128\n",
      "step:1936,train_loss:0.017201369628310204,train_acc:0.9985119104385376\n",
      "step:1937,train_loss:0.020495528355240822,train_acc:0.996279776096344\n",
      "step:1938,train_loss:0.01790393330156803,train_acc:0.9947916865348816\n",
      "step:1939,train_loss:0.0163902435451746,train_acc:0.9977678656578064\n",
      "step:1940,train_loss:0.01719459518790245,train_acc:0.9970238208770752\n",
      "step:1941,train_loss:0.026884164661169052,train_acc:0.9910714030265808\n",
      "step:1942,train_loss:0.01643185317516327,train_acc:0.996279776096344\n",
      "step:1943,train_loss:0.018119703978300095,train_acc:0.9947916865348816\n",
      "step:1944,train_loss:0.028213365003466606,train_acc:0.9910714030265808\n",
      "step:1945,train_loss:0.029638875275850296,train_acc:0.991815447807312\n",
      "step:1946,train_loss:0.018246877938508987,train_acc:0.9947916865348816\n",
      "step:1947,train_loss:0.016559649258852005,train_acc:0.9977678656578064\n",
      "step:1948,train_loss:0.015982069075107574,train_acc:0.9955357313156128\n",
      "step:1949,train_loss:0.014276843518018723,train_acc:0.9977678656578064\n",
      "step:1950,train_loss:0.01229027472436428,train_acc:0.9992559552192688\n",
      "val_acc:0.9972718358039856\n",
      "step:1951,train_loss:0.017871743068099022,train_acc:0.9970238208770752\n",
      "step:1952,train_loss:0.023529937490820885,train_acc:0.9940476417541504\n",
      "step:1953,train_loss:0.01847514882683754,train_acc:0.9955357313156128\n",
      "step:1954,train_loss:0.01659397780895233,train_acc:0.9955357313156128\n",
      "step:1955,train_loss:0.027600906789302826,train_acc:0.991815447807312\n",
      "step:1956,train_loss:0.014902986586093903,train_acc:0.9985119104385376\n",
      "step:1957,train_loss:0.01965833082795143,train_acc:0.9955357313156128\n",
      "step:1958,train_loss:0.012942967005074024,train_acc:0.996279776096344\n",
      "step:1959,train_loss:0.014744910411536694,train_acc:0.9977678656578064\n",
      "step:1960,train_loss:0.013770381920039654,train_acc:0.9992559552192688\n",
      "step:1961,train_loss:0.022850826382637024,train_acc:0.9933035969734192\n",
      "step:1962,train_loss:0.01705961488187313,train_acc:0.9947916865348816\n",
      "step:1963,train_loss:0.01607016660273075,train_acc:0.9970238208770752\n",
      "step:1964,train_loss:0.02069397270679474,train_acc:0.9947916865348816\n",
      "step:1965,train_loss:0.025389041751623154,train_acc:0.991815447807312\n",
      "step:1966,train_loss:0.01667071506381035,train_acc:0.9955357313156128\n",
      "step:1967,train_loss:0.0220938790589571,train_acc:0.9947916865348816\n",
      "step:1968,train_loss:0.014527871273458004,train_acc:0.9977678656578064\n",
      "step:1969,train_loss:0.01621342822909355,train_acc:0.996279776096344\n",
      "step:1970,train_loss:0.023388121277093887,train_acc:0.9955357313156128\n",
      "step:1971,train_loss:0.02088380791246891,train_acc:0.9940476417541504\n",
      "step:1972,train_loss:0.022846510633826256,train_acc:0.9940476417541504\n",
      "step:1973,train_loss:0.018363965675234795,train_acc:0.9970238208770752\n",
      "step:1974,train_loss:0.021636124700307846,train_acc:0.9940476417541504\n",
      "step:1975,train_loss:0.017411069944500923,train_acc:0.996279776096344\n",
      "step:1976,train_loss:0.03025406040251255,train_acc:0.9888392686843872\n",
      "step:1977,train_loss:0.015072392299771309,train_acc:0.9955357313156128\n",
      "step:1978,train_loss:0.015204526484012604,train_acc:0.9947916865348816\n",
      "step:1979,train_loss:0.018225762993097305,train_acc:0.996279776096344\n",
      "step:1980,train_loss:0.02074720524251461,train_acc:0.9933035969734192\n",
      "step:1981,train_loss:0.01628033071756363,train_acc:0.9977678656578064\n",
      "step:1982,train_loss:0.018918415531516075,train_acc:0.9940476417541504\n",
      "step:1983,train_loss:0.017561210319399834,train_acc:0.9977678656578064\n",
      "step:1984,train_loss:0.018537674099206924,train_acc:0.9955357313156128\n",
      "step:1985,train_loss:0.019042739644646645,train_acc:0.9933035969734192\n",
      "step:1986,train_loss:0.02533256635069847,train_acc:0.9933035969734192\n",
      "step:1987,train_loss:0.033966705203056335,train_acc:0.988095223903656\n",
      "step:1988,train_loss:0.022517791017889977,train_acc:0.992559552192688\n",
      "step:1989,train_loss:0.019385743886232376,train_acc:0.996279776096344\n",
      "step:1990,train_loss:0.01365663856267929,train_acc:0.9977678656578064\n",
      "step:1991,train_loss:0.01889413595199585,train_acc:0.9947916865348816\n",
      "step:1992,train_loss:0.02242782898247242,train_acc:0.9947916865348816\n",
      "step:1993,train_loss:0.020074736326932907,train_acc:0.9947916865348816\n",
      "step:1994,train_loss:0.014814961701631546,train_acc:0.9970238208770752\n",
      "step:1995,train_loss:0.01873132772743702,train_acc:0.9955357313156128\n",
      "step:1996,train_loss:0.013140469789505005,train_acc:0.9977678656578064\n",
      "step:1997,train_loss:0.01896895281970501,train_acc:0.996279776096344\n",
      "step:1998,train_loss:0.014016357250511646,train_acc:0.9985119104385376\n",
      "step:1999,train_loss:0.018953446298837662,train_acc:0.9955357313156128\n",
      "step:2000,train_loss:0.017039261758327484,train_acc:0.9947916865348816\n",
      "val_acc:0.9992559552192688\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('input'):\n",
    "    # 占位符\n",
    "    x = tf.placeholder(tf.float32, shape=[None, h, w, c], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 42, 2], name='y_')\n",
    "    is_train = tf.placeholder(tf.bool)\n",
    "\n",
    "logits = mobilenetv2(x, num_class, is_train)\n",
    "pre = tf.reshape(logits, [-1, 42, 2])\n",
    "res = tf.nn.softmax(pre,name='res')\n",
    "\n",
    "b = tf.constant(value=1, dtype=tf.float32)\n",
    "logits_eval = tf.multiply(pre, b, name='logits_eval')\n",
    "\n",
    "global_step = tf.Variable(0)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    with tf.name_scope('corss_entropy'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pre, labels=y_))\n",
    "        tf.summary.scalar('corss_entropy', loss)\n",
    "    with tf.name_scope('train_op'):\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss, global_step=global_step)\n",
    "\n",
    "with tf.name_scope('acc'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        max_idx_p = tf.argmax(res, 2)\n",
    "        max_idx_l = tf.argmax(y_, 2)\n",
    "        correct = tf.equal(max_idx_p, max_idx_l)\n",
    "    with tf.name_scope('accuary'):\n",
    "        acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        tf.summary.scalar('accuary', acc)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # summary_writer\n",
    "    train_writer = tf.summary.FileWriter(summary_path, tf.get_default_graph())\n",
    "    # 变量初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # 启动多线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    max_ac = 0\n",
    "    # training\n",
    "    for step in range(n_step):\n",
    "        bx,by = sess.run([batch_x,batch_y])\n",
    "        feed_dict = {x: bx, y_: by, is_train: True}\n",
    "        train_sum, _, err, ac = sess.run([merged, train_op, loss, acc], feed_dict=feed_dict)\n",
    "        print(\"step:{},train_loss:{},train_acc:{}\".format(step, err, ac))\n",
    "        train_writer.add_summary(train_sum, step)\n",
    "            \n",
    "        # validation\n",
    "        vac = 0\n",
    "        if step%50 == 0:\n",
    "            for vv in range(3):\n",
    "                vbx,vby = sess.run([vbatch_x,vbatch_y])\n",
    "                feed_dict = {x: vbx, y_: vby, is_train: False}\n",
    "                v_ac = sess.run(acc, feed_dict=feed_dict)\n",
    "                vac += v_ac\n",
    "            print(\"val_acc:{}\".format(vac/3))    \n",
    "            if vac>max_ac:\n",
    "                max_ac = vac\n",
    "                saver.save(sess, model_path, global_step=global_step)\n",
    "                        \n",
    "                \n",
    "\n",
    "    train_writer.close()\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
